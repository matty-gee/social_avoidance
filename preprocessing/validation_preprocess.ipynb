{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "from datetime import date\n",
    "import math\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "import sys\n",
    "\n",
    "main_dir = '/Users/matty_gee/Desktop/SNT/SNT-behavior'\n",
    "sys.path.insert(0, main_dir + '/code')\n",
    "# from code_base import *\n",
    "from data_prep_utils import * \n",
    "from os.path import exists\n",
    "from compute_task_variables import *\n",
    "\n",
    "# dumb to have different orders everywhere...should just be explicit...\n",
    "img_sets = {'OFA': ['OlderFemaleBl_2','OlderMaleW_1','OlderMaleW_4','OlderFemaleBr_3','OlderMaleBr_2','OlderFemaleW_1'],\n",
    "            'OFB': ['OlderFemaleW_2','OlderMaleBr_1','OlderMaleBl_3','OlderFemaleW_3','OlderMaleW_5','OlderFemaleBl_1'],\n",
    "            'OFC': ['OlderFemaleBl_2','OlderMaleBr_1','OlderMaleW_5','OlderFemaleW_3','OlderMaleBr_4','OlderFemaleW_1'],\n",
    "            'OFD': ['OlderFemaleW_2','OlderMaleW_1','OlderMaleBr_3','OlderFemaleBr_3','OlderMaleW_5','OlderFemaleBl_1'],\n",
    "            'OMA': ['OlderMaleBr_2','OlderFemaleW_2','OlderFemaleW_3','OlderMaleBr_1','OlderFemaleBr_5','OlderMaleW_5'],\n",
    "            'OMB': ['OlderMaleW_1','OlderFemaleBl_2','OlderFemaleBl_3','OlderMaleW_4','OlderFemaleW_1','OlderMaleBr_4'], \n",
    "            'OMC': ['OlderMaleBr_4','OlderFemaleBl_2','OlderFemaleW_3','OlderMaleW_3','OlderFemaleBl_1','OlderMaleW_5'],\n",
    "            'OMD': ['OlderMaleW_1','OlderFemaleW_2','OlderFemaleBr_5','OlderMaleBr_3','OlderFemaleW_1','OlderMaleBr_4'],\n",
    "            'YFA': ['YoungerFemaleBr_1','YoungerMaleW_4','YoungerMaleW_3','OlderFemaleBr_5','OlderMaleBr_4','OlderFemaleW_1'],\n",
    "            'YFB': ['YoungerFemaleW_3','YoungerMaleBr_2','OlderMaleBr_3','OlderFemaleW_4','YoungerMaleW_2','OlderFemaleBl_1'],\n",
    "            'YFC': ['YoungerFemaleBr_1','YoungerMaleBr_2','OlderMaleW_4','OlderFemaleW_3','OlderMaleBr_4','OlderFemaleW_1'],\n",
    "            'YFD': ['YoungerFemaleW_3','YoungerMaleW_4','OlderMaleBr_3','OlderFemaleBr_5','OlderMaleW_5','OlderFemaleBl_1'],\n",
    "            'YMA': ['YoungerMaleBr_2','YoungerFemaleW_3','OlderFemaleW_4','OlderMaleBr_3','OlderFemaleBl_1','YoungerMaleW_2'],\n",
    "            'YMB': ['YoungerMaleW_4','YoungerFemaleBr_1','OlderFemaleBr_5','YoungerMaleW_3','OlderFemaleW_1','OlderMaleBr_4'],\n",
    "            'YMC': ['YoungerMaleBr_2','YoungerFemaleBr_1','OlderFemaleW_3','OlderMaleW_3','OlderFemaleBl_1','OlderMaleW_5'],\n",
    "            'YMD': ['YoungerMaleW_4','YoungerFemaleW_3','OlderFemaleBr_3','OlderMaleBr_3','OlderFemaleW_1','OlderMaleBr_4']}\n",
    "\n",
    "# info about the validted decisions: e.g., the continuous ratings etc..\n",
    "decisions_info = pd.read_excel(main_dir + '/Online/Prolific/Info/TaskValidation_Val20_SortedOptionMeans_Mem50_n81.xlsx')\n",
    "decisions_info = decisions_info.sort_values(by = 'Decision').reset_index(drop=True)\n",
    "character_roles = ['first', 'second', 'assistant', 'powerful', 'boss', 'neutral'] # order in matlab\n",
    "\n",
    "data_dir = main_dir + '/Online/Prolific/Data/Replication_2022'\n",
    "pavlovia_dir = '/Users/matthew/Desktop/social-navigation/data'\n",
    "repl_data_dir = data_dir + '/Task/Raw-Pavlovia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get pavlovia files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "for file in glob.glob(pavlovia_dir + \"/*.csv\"):\n",
    "    try:\n",
    "        data = pd.read_csv(file)\n",
    "        sub  = data['prolific_id'].values[0]\n",
    "        exp  = data['experiment'].values[0]\n",
    "        if (sub != '6168883c6837227155b2360e') & (isinstance(sub, str)): # avoid my prolific id (but there are other ones too) & ones without prolific ids\n",
    "            if exp == 'behavioral':\n",
    "                if '2022-02' in file:\n",
    "                    cp_file = repl_data_dir + '/' + file.split('/')[-1]   \n",
    "            if not exists(cp_file):\n",
    "                shutil.copyfile(file, cp_file)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    }
   ],
   "source": [
    "sub_files = [sub_data for sub_data in glob.glob(repl_data_dir + \"/*.csv\")]\n",
    "print(len(sub_files))\n",
    "\n",
    "missing = []\n",
    "posttask_dfs = []\n",
    "dates = []\n",
    "\n",
    "for file in sub_files:\n",
    "    data = pd.read_csv(file)\n",
    "    sub_id = data['prolific_id'].values[0]\n",
    "    if sub_id not in ['5fb28e64134ec0894396633a', '60393e9ddde61e3a5463746d', '5fb28e64134ec0894396633a']:\n",
    "        if data.shape[0] > 1: data = pd.DataFrame(data.iloc[0,:]).T # sometimes saves multiple times into diff rowss..?\n",
    "        data.replace('newcomb','powerful', inplace=True)\n",
    "        data.replace('hayworth','boss', inplace=True)\n",
    "        data.columns = data.columns.str.replace(\"newcomb\", \"powerful\")\n",
    "        data.columns = data.columns.str.replace(\"hayworth\", \"boss\")\n",
    "        \n",
    "        date = file.split('/')[-1].split('_')[3]        \n",
    "        \n",
    "        ############################################################\n",
    "        # narrative task\n",
    "        ############################################################\n",
    "\n",
    "        narrative_fname = data_dir + '/Task/Organized/SNT_' + sub_id + '.xlsx'\n",
    "        if not exists(narrative_fname):\n",
    "            try: \n",
    "                \n",
    "                narrative_resp = np.array([int(re.sub('[\"\\]\"]', '', d.split(':')[1])) for d in data['narrative.choices'].values[0].split(',')])\n",
    "                narrative_opt_order = data['narrative.opts_order'].values[0].split('\",\"')\n",
    "                narrative_resp_data = np.zeros(len(narrative_resp))\n",
    "                affl = []\n",
    "                pwr  = []\n",
    "                for q, question in enumerate(narrative_opt_order):\n",
    "                    question = ''.join(filter(lambda item: not item.isdigit(), question))\n",
    "                    for sep in [';', ',\"', '.,']:\n",
    "                        if sep in question:\n",
    "                            opt1 = remove_nontext(question.split(sep)[1])\n",
    "                            opt2 = remove_nontext(question.split(sep)[2])\n",
    "                    sort_ix = np.argsort((opt1,opt2)) # order options alphabetically\n",
    "                    resp = sort_ix[narrative_resp[q]-1]+1 # choice -> 1 or 2, depending on alphabetical ordering\n",
    "                    narrative_resp_data[q] = resp\n",
    "                    decision = decisions_info.iloc[q]\n",
    "                    affl.append(decision['Opt{}_Affl_Discrete'.format(int(resp))])\n",
    "                    pwr.append(decision['Opt{}_Pwr_Discrete'.format(int(resp))])\n",
    "                narrative_rts = np.array([int(remove_nontext(rt)) for rt in data['narrative.rts'].values[0].split(',')])\n",
    "                decision_rts  = narrative_rts[np.array(decisions_info['Slide_num'])-1]\n",
    "                narrative_df = pd.DataFrame((narrative_resp, affl, pwr, decision_rts)).T\n",
    "                narrative_df.columns = ['button_press', 'affil', 'power', 'rt']\n",
    "                narrative_df.insert(0, 'trial_num', np.arange(1,64))\n",
    "                narrative_df.to_excel(narrative_fname, index=False)\n",
    "\n",
    "            except:\n",
    "                # if no task, just skip\n",
    "                continue\n",
    "            \n",
    "        ############################################################\n",
    "        # memory\n",
    "        ############################################################\n",
    "\n",
    "        try: \n",
    "            \n",
    "            mem_cols = [c for c in data.columns if 'memory' in c]\n",
    "            mem_ques = data[[c for c in mem_cols if 'question' in c]].values[0]\n",
    "            mem_resp = data[[c for c in mem_cols if 'resp' in c]].values[0]\n",
    "            mem_rt = data[[c for c in mem_cols if 'rt' in c]].values[0]\n",
    "            mem_data = sorted(list(zip(mem_ques, mem_resp)))\n",
    "\n",
    "            # summary \n",
    "            mem_correct = [1,4,5,4,5,0,0,0,4,1,3,3,1,4,5,3,1,0,2,5,5,2,2,2,3,3,0,1,2,4] # alphabetical for memry qs, according to the order of matlab outputs\n",
    "            mem_acc = np.zeros(6) \n",
    "            for r,resp in enumerate(mem_data): \n",
    "                if resp[1] == character_roles[mem_correct[r]]:\n",
    "                    mem_acc[mem_correct[r]]+=1\n",
    "            mem_acc_df = pd.DataFrame((mem_acc/5).reshape(1,-1), columns=['memory_' + char for char in character_roles])\n",
    "            mem_acc_df.insert(6, 'memory_mean', np.mean(mem_acc_df.values))\n",
    "            mem_acc_df.insert(6, 'memory_rt', np.mean(mem_rt))\n",
    "\n",
    "            # trial x trial\n",
    "            mem_questions = ['memory_' + str(q+1) + '_'  + character_roles[r] for q,r in enumerate(mem_correct)]\n",
    "            mem_responses = [character_roles[character_roles.index(resp[1])] for r,resp in enumerate(mem_data)] # find the role of the character response\n",
    "            mem_resp_df = pd.DataFrame(np.array(mem_responses).reshape(1,-1), columns=mem_questions)\n",
    "\n",
    "            mem_df = pd.concat([mem_acc_df, mem_resp_df],1)\n",
    "            \n",
    "        except: \n",
    "            # if no memory just skip\n",
    "            continue\n",
    "\n",
    "        ############################################################\n",
    "        # demos of the characters \n",
    "        ############################################################\n",
    "\n",
    "        try: \n",
    "            \n",
    "            char_skincolor = []\n",
    "            char_gender = []\n",
    "            for char in character_roles: \n",
    "                img = data['character_info.' + char + '.img'].values[0]\n",
    "                if 'Br_' in img: char_skincolor.append('brown')\n",
    "                else: char_skincolor.append('white')\n",
    "                if 'Male' in img: char_gender.append('man')\n",
    "                else: char_gender.append('woman')\n",
    "            gender_df = pd.DataFrame(np.array(char_gender).reshape(1,-1), columns=['gender_' + role for role in character_roles])\n",
    "            skincolor_df = pd.DataFrame(np.array(char_skincolor).reshape(1,-1), columns=['skincolor_' + role for role in character_roles])\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "                \n",
    "        ############################################################\n",
    "        # post-task\n",
    "        ############################################################\n",
    "\n",
    "        try: \n",
    "            \n",
    "            ############\n",
    "            # demo: get mean\n",
    "            ############\n",
    "            \n",
    "            demo_df = get_and_rename(data, 'demographics')\n",
    "            dims = ['masculine', 'feminine', 'youthful']\n",
    "            for dim in dims: \n",
    "                mean_rating = np.mean(demo_df[[c for c in demo_df.columns if dim + '.resp' in c]],1).values[0]\n",
    "                mean_rt = np.mean(demo_df[[c for c in demo_df.columns if dim + '.rt' in c]],1).values[0]\n",
    "                demo_df.insert(0, 'mean.' + dim, mean_rating)\n",
    "                demo_df.insert(1, 'mean.' + dim + '.rt', mean_rt)\n",
    "\n",
    "            ############\n",
    "            # dots: normalize & get mean\n",
    "            ############\n",
    "            \n",
    "            dots_df = data[[c for c in data.columns if 'dots.' in c]]\n",
    "            for col in dots_df.columns: # rename\n",
    "                split_col = col.split('.')\n",
    "                rename_col = split_col[0] + '_' + split_col[2] + '_' + split_col[1]\n",
    "                dots_df.rename(columns={col:rename_col}, inplace=True)\n",
    "                \n",
    "            dots_affil = (dots_df[[c for c in dots_df.columns if ('affil' in c) & ('redos' not in c)]] - 500)/500\n",
    "            dots_affil.insert(0, 'dots_affil_mean', np.mean(dots_affil, 1))\n",
    "            dots_power = (500 - dots_df[[c for c in dots_df.columns if ('power' in c) & ('redos' not in c) & ('affil' not in c)]])/500\n",
    "            dots_power.insert(0, 'dots_power_mean', np.mean(dots_power, 1))\n",
    "            dots_df = pd.concat([dots_affil, dots_power], 1)\n",
    "\n",
    "            ############\n",
    "            # judgments: get mean\n",
    "            ############\n",
    "            \n",
    "            judgments_df = get_and_rename(data, 'judgments')\n",
    "            dims = ['similarity', 'friendliness', 'competence', 'popularity', 'dominance', \n",
    "                    'likability', 'likability_self', 'impact', # unfortunately did not collect impact on self ratings yet...\n",
    "                    'intensity', 'stability']\n",
    "            for dim in dims: \n",
    "                mean_rating = np.mean(judgments_df[[c for c in judgments_df.columns if (dim + '.resp' in c) & ('self_self' not in c)]],1).values[0]\n",
    "                mean_rt = np.mean(judgments_df[[c for c in judgments_df.columns if (dim + '.rt' in c) & ('self_self' not in c)]],1).values[0]\n",
    "                judgments_df.insert(0, 'mean.' + dim + '.resp', mean_rating)\n",
    "                judgments_df.insert(1, 'mean.' + dim + '.rt', mean_rt)\n",
    "\n",
    "                \n",
    "                \n",
    "            ############\n",
    "            # choice data - organize\n",
    "            ############\n",
    "            \n",
    "            comparisons = [['assistant','first'], ['assistant','hayworth'], ['assistant','neutral'], ['assistant','newcomb'], ['assistant','second'], \n",
    "                          ['first','hayworth'], ['first','neutral'], ['first','newcomb'], ['first','second'],\n",
    "                          ['hayworth','neutral'], ['hayworth','newcomb'], ['hayworth','second'], ['neutral','newcomb'], ['neutral','second'], ['newcomb','second']]\n",
    "            columns = []\n",
    "            for c,comp in enumerate(comparisons):\n",
    "                columns.append('forced_choice_' + str(c+1) + '_' + comp[0])\n",
    "                columns.append('forced_choice_' + str(c+1) + '_' + comp[1])\n",
    "                columns.append('forced_choice_' + str(c+1) + '_side')\n",
    "            choice_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "            try:\n",
    "                \n",
    "                choice_df_ = data[[c for c in data.columns if 'forced_choice' in c]]\n",
    "                choice_data = []\n",
    "                choice_cols = []\n",
    "                for t in np.arange(0,15):\n",
    "                    options = choice_df_['forced_choice.' + str(t) + '.comparison'].values[0].split('_&_')\n",
    "                    resp = choice_df_['forced_choice.' + str(t) + '.resp'].values[0] - 50\n",
    "                    if resp < 0: \n",
    "                        side = 'L'\n",
    "                        choice = options[0]\n",
    "                    else: \n",
    "                        side = 'R' \n",
    "                        choice = options[1]\n",
    "                    ans = np.array([0,0])\n",
    "                    sorted_ = sorted(options)\n",
    "                    ans_ix = sorted_.index(choice)\n",
    "                    ans[ans_ix] = np.abs(resp)\n",
    "                    ans[np.abs(ans_ix-1)] = -np.abs(resp)\n",
    "\n",
    "                    choice_cols.extend(['forced_choice.' + str(t) + '_' + sorted_[0], 'forced_choice.' + str(t) + '_' + sorted_[1], 'forced_choice.' + str(t) + '_side'])\n",
    "                    choice_data.append([('+').join(sorted_)] + list(ans) + list(side))\n",
    "\n",
    "                sort_df = pd.DataFrame(np.array(choice_data))\n",
    "                sort_df = sort_df.sort_values(0, ascending=True).reset_index(drop=True)\n",
    "                choice_df.loc[0,:] = sort_df.values[:,1:].flatten()\n",
    "                \n",
    "            except: \n",
    "                pass\n",
    "                \n",
    "            choice_df.columns = choice_df.columns.str.replace(\"newcomb\", \"powerful\")\n",
    "            choice_df.columns = choice_df.columns.str.replace(\"hayworth\", \"boss\")\n",
    "            for char in character_roles:\n",
    "                choice_df['forced_choice_mean_' + char] = np.mean(choice_df[[c for c in choice_df.columns if char in c]].values.astype(int))\n",
    "            \n",
    "            ############\n",
    "            # others - no changes\n",
    "            ############\n",
    "            \n",
    "            race_df = data[[c for c in data.columns if 'race' in c]]\n",
    "            free_resp_df = data[[c for c in data.columns if 'character_free_responses' in c]]\n",
    "            story_ques_df = data[[c for c in data.columns if 'storyline_questions' in c]] \n",
    "            beh_ques_df = data[[c for c in data.columns if 'behavior_questions' in c]] \n",
    "\n",
    "            post_df = pd.concat([mem_df, gender_df, skincolor_df, demo_df, race_df, dots_df, judgments_df, choice_df, free_resp_df, story_ques_df, beh_ques_df], axis=1)\n",
    "\n",
    "            # rename columns\n",
    "            dims = ['youthful', 'feminine', 'masculine', 'race', 'stability', 'intensity', \n",
    "                    'impact', 'likability', 'dominance', 'competence', 'friendliness', 'similarity', 'popularity']\n",
    "            for dim in dims: \n",
    "                col_names = [c for c in post_df.columns if dim in c]\n",
    "                for col in col_names:\n",
    "                    split_name = col.split('.')\n",
    "                    rename = split_name[1] + '_' + split_name[0]\n",
    "                    if 'rt' in col: rename = rename + '_rt'\n",
    "                    post_df.rename(columns={col:rename}, inplace=True)\n",
    "\n",
    "            ############\n",
    "            # iq\n",
    "            ############      \n",
    "\n",
    "            iq_ques = [q.split('.')[1] for q in [c for c in data.columns if ('iq' in c) & ('resp' in c)]]\n",
    "            iq_resp = data[[c for c in data.columns if ('iq' in c) & ('resp' in c)]].values[0]\n",
    "            iq_rt = data[[c for c in data.columns if ('iq' in c) & ('rt' in c)]].values[0]\n",
    "\n",
    "            answers =  [[\"VR4\",5],[\"VR16\",\"Its\"],[\"VR17\",47],[\"VR19\",\"Sunday\"],\n",
    "                        [\"LN7\",\"X\"],[\"LN33\",\"G\"],[\"LN34\",\"X\"],[\"LN58\",\"N\"],\n",
    "                        [\"MX45\",\"E\"],[\"MX46\",\"B\"],[\"MX47\",\"B\"],[\"MX55\",\"D\"],\n",
    "                        [\"R3D3\",\"C\"],[\"R3D4\",\"B\"],[\"R3D6\",\"F\"],[\"R3D8\",\"G\"]]\n",
    "            iq_correct = np.zeros(len(answers))\n",
    "            for answer in answers: \n",
    "                for (q,ques), resp in zip(enumerate(iq_ques), iq_resp):\n",
    "                    if (ques == answer[0]) & (resp == answer[1]):\n",
    "                        iq_correct[q] = 1\n",
    "\n",
    "            post_df.insert(0, 'iq_score', np.mean(iq_correct))\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            missing.append(['posttask', file.split('/')[-1]])\n",
    "            pass\n",
    "\n",
    "        ############################################################\n",
    "        # realworld\n",
    "        ############################################################  \n",
    "\n",
    "        # sni stuff\n",
    "        num_ppl = []\n",
    "        network_div = []\n",
    "         \n",
    "        # enforce a dating column - not everyone will have\n",
    "        categories = ['Marriage','Dating','Children','Parents','Inlaws','Relatives','Friends','Religion','School',\n",
    "                      'Work','Work_supervision','Work_nonsupervision','Neighbors','Volunteer',\n",
    "                      'Extra_group1', 'Extra_group2', 'Extra_group3', 'Extra_group4', 'Extra_group5'] \n",
    "        for cat in categories:\n",
    "            try:\n",
    "                resp = data['realworld_relationships.' + cat + '.number_of_people.value'].values[0]\n",
    "                if cat == 'Dating':\n",
    "                    if (resp == 1):\n",
    "                        network_div.append(1)\n",
    "                        num_ppl.append(1)\n",
    "                    elif (resp == 3): \n",
    "                        network_div.append(1)\n",
    "                        num_ppl.append(2)\n",
    "                    elif (resp == 2) or (resp == 4): \n",
    "                        network_div.append(0)\n",
    "                        num_ppl.append(0) \n",
    "                else:\n",
    "                    if math.isnan(resp):\n",
    "                        num_ppl.append(0)\n",
    "                        network_div.append(0)\n",
    "                    else:\n",
    "                        num_ppl.append(resp)\n",
    "                        if (resp != 0):\n",
    "                            network_div.append(1)\n",
    "                        else:\n",
    "                            network_div.append(0)\n",
    "            except: \n",
    "                num_ppl.append(0)\n",
    "                network_div.append(0)\n",
    "\n",
    "        sni_df = pd.DataFrame(np.array([np.sum(num_ppl), np.sum(network_div)]).reshape(1,-1), columns=['sni_number_ppl', 'sni_network_diversity'])\n",
    "        initials_ = [c for c in data.columns if ('realworld' in c) & ('initials' in c)]\n",
    "        realworld = []\n",
    "        for initials in initials_:\n",
    "            category = initials.split('.')[1]\n",
    "            person_ = initials.split('.initials')[0]\n",
    "            cols = ['time_known', 'frequency', 'similarity', \n",
    "                    'likability', 'impact', \n",
    "                    'popularity', 'competence', 'friendliness', 'dominance', \n",
    "                    'dots_affil', 'dots_power']\n",
    "            # only allowed up to 10 in the dots... so might not be some columns even if there are initials\n",
    "            try:\n",
    "                resps = data[[person_ + '.' + col for col in cols]].values[0]\n",
    "                realworld.append(list([category]) + list(resps))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        realworld_df = pd.DataFrame(realworld, columns=['realworld_category'] + ['realworld_' + col for col in cols])\n",
    "        realworld_df['realworld_dots_affil'] = (realworld_df['realworld_dots_affil'] - 500)/500\n",
    "        realworld_df['realworld_dots_power'] = (500 - realworld_df['realworld_dots_power'])/500\n",
    "        realworld_data = realworld_df.values.flatten()\n",
    "        columns = np.array([['realworld_category.' + str(i)] + ['realworld_' + col  + '.' + str(i) for col in cols] for i in np.arange(1,11)]).flatten()\n",
    "        realworld_df = pd.DataFrame(columns=list(columns))\n",
    "        realworld_df.loc[0,0:len(realworld_data)] = list(realworld_data)\n",
    "\n",
    "        # put it all together\n",
    "        posttask_df = pd.concat([post_df, sni_df, realworld_df],1)\n",
    "        posttask_df.insert(0, 'sub_id', sub_id)\n",
    "        posttask_df.insert(1, 'date', date)\n",
    "        posttask_df.reset_index(drop=True, inplace=True)\n",
    "        posttask_dfs.append(posttask_df)\n",
    "        \n",
    "posttask = pd.concat(posttask_dfs)\n",
    "posttask.to_excel(data_dir + '/Summary/Posttask-replication_summary_n' + str(len(posttask)) + '.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redcap\n",
    "Dl Csvs first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jq/pk75wqp554g5dhplx1d3m91h0000gw/T/ipykernel_64815/1521642209.py:89: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  csv_df = pd.concat([ipip_df, ius_df, sss_df, aes_df, demo_df, oci_df, bapq_df, apdis_df, lsas_df, zbpd_df, sds_df],1)\n"
     ]
    }
   ],
   "source": [
    "questionnaire_csvs = glob.glob(data_dir + \"/Questionnaires/*.csv\")\n",
    "csv_dfs = []\n",
    "for csv in questionnaire_csvs: \n",
    "    \n",
    "    raw_df = pd.read_csv(csv)\n",
    "    raw_df = raw_df[[c for c in raw_df if 'complete' not in c and 'timestamp' not in c]]\n",
    "    \n",
    "    # demos\n",
    "    demo_df = subset_df(raw_df, ['demo'])\n",
    "    demo_df.rename(columns = {'demo_race___1': 'demo_race_amer_indian_or_alaska_native',\n",
    "                             'demo_race___2': 'demo_race_asian',\n",
    "                             'demo_race___3': 'demo_race_black/aa',\n",
    "                             'demo_race___4': 'demo_race_latino/hispanic',\n",
    "                             'demo_race___5': 'demo_race_multiracial',\n",
    "                             'demo_race___6': 'demo_race_nat_hawaiian_or_pac_isl',\n",
    "                             'demo_race___7': 'demo_race_white',\n",
    "                             'demo_race___8': 'demo_race_other',\n",
    "                             'demo_race_other': 'demo_race_other_text',\n",
    "                             'demo_sex': 'demo_sex_1F',\n",
    "                             'demo_gender': 'demo_gender_1W',\n",
    "                             'demo_handedness': 'demo_handedness_1R'}, \n",
    "                    inplace = True)\n",
    "\n",
    "    # oci\n",
    "    oci_df = subset_df(raw_df, ['oci'])\n",
    "    oci_df['oci_score'] = np.sum(oci_df, axis=1)\n",
    "    oci_df['oci_att'] = raw_df['oci_att']\n",
    "\n",
    "    # bapq\n",
    "    bapq_df = score_bapq(raw_df) # includes items\n",
    "\n",
    "    # apdis\n",
    "    apdis_df = raw_df[['apdis_score', 'apdis_att'] + ['apdis_' + str(i) for i in np.arange(1,9)]]\n",
    "\n",
    "    # lsas_av\n",
    "    lsas_df = raw_df[['lsas_av_score', 'lsas_av_att'] + ['lsas_av_' + str(i) for i in np.arange(1,25)]]\n",
    "\n",
    "    # zbpd\n",
    "    zbpd_df = raw_df[['zbpd_score', 'zbpd_att'] + ['zbpd_' + str(i) for i in np.arange(1,11)]]\n",
    "\n",
    "    # sds\n",
    "    sds_df_ = subset_df(raw_df, ['sds'])\n",
    "    sds_df = reverse_score(sds_df_, 4, sds_rev)\n",
    "    sds_df['sds_score'] = np.sum(sds_df, axis=1)\n",
    "    sds_df['sds_att'] = raw_df['sds_att']\n",
    "\n",
    "    # aes\n",
    "    # -- some are reversed (4,3,2,1): 1,2,3,4,5,7,8,9,12,13,14,15,16,17,18\n",
    "    aes_raw = raw_df[['aes_' + str(s) for s in np.arange(1,19)]].values\n",
    "    aes_raw[aes_raw == 3] = 4\n",
    "    aes_raw[aes_raw == 2] = 3\n",
    "    aes_raw[aes_raw == 0] = 1\n",
    "    aes_df_ = pd.DataFrame(aes_raw, columns=raw_df[['aes_' + str(s) for s in np.arange(1,19)]].columns.values)\n",
    "\n",
    "    aes_df  = reverse_score(aes_df_, 4, aes_rev)\n",
    "    aes_df['aes_score'] = np.sum(aes_df, axis=1)\n",
    "    aes_df['aes_cog_score'] = np.sum(aes_df.iloc[:,np.array([1,3,4,5,8,11,12,15])-1], axis=1)\n",
    "    aes_df['aes_beh_score'] = np.sum(aes_df.iloc[:,np.array([2,6,9,10,12])-1], axis=1)\n",
    "    aes_df['aes_emt_score'] = np.sum(aes_df.iloc[:,np.array([7,14])-1], axis=1)\n",
    "    aes_df['aes_oth_score'] = np.sum(aes_df.iloc[:,np.array([15,17,18])-1], axis=1)\n",
    "    aes_df['aes_att'] = raw_df['aes_att'] \n",
    "\n",
    "    # sss\n",
    "    sss_df = score_sss(raw_df) # includes items\n",
    "\n",
    "    # ipip\n",
    "    ipip_rev = np.array([6,7,8,9,10,15,16,17,18,19,20])-1\n",
    "    ipip_df = reverse_score(raw_df[['mini_ipip_' + str(s) for s in np.arange(1,21)]], 5, ipip_rev)\n",
    "    extraversion = np.sum(ipip_df.iloc[:, np.array([1,6,11,16])-1],1)\n",
    "    agreeableness = np.sum(ipip_df.iloc[:,np.array([2,7,12,17])-1],1)\n",
    "    conscientiousness = np.sum(ipip_df.iloc[:,np.array([3,8,13,18])-1],1)\n",
    "    neuroticism = np.sum(ipip_df.iloc[:,np.array([4,9,14,19])-1],1)\n",
    "    intellect = np.sum(ipip_df.iloc[:,np.array([5,10,15,20])-1],1)\n",
    "    ipip_df.insert(0, 'mini_ipip_extraversion', extraversion)\n",
    "    ipip_df.insert(1, 'mini_ipip_agreeableness', agreeableness)\n",
    "    ipip_df.insert(2, 'mini_ipip_conscientiousness', conscientiousness)\n",
    "    ipip_df.insert(3, 'mini_ipip_neuroticism', neuroticism)\n",
    "    ipip_df.insert(4, 'mini_ipip_intellect', intellect)\n",
    "\n",
    "    # ius\n",
    "    ius_df = raw_df[['ius_' + str(s) for s in np.arange(1,28)]]\n",
    "    ius_1 = np.sum(ius_df.iloc[:,np.array([1,2,3,9,12,13,14,15,16,17,20,22,23,24,25])-1],1).values # f1 - negative behavioral and self-reverent implicationss\n",
    "    ius_2 = np.sum(ius_df.iloc[:,np.array([4,5,6,7,8,10,11,18,19,21,26,27])-1],1).values # f2 - uncertainty is unfair \n",
    "    ius_df.insert(1, 'ius_f1', ius_1)\n",
    "    ius_df.insert(2, 'ius_f2', ius_2)    \n",
    "    ius_df.insert(0, 'ius_score', ius_1 + ius_2) \n",
    "\n",
    "    # put together\n",
    "    csv_df = pd.concat([ipip_df, ius_df, sss_df, aes_df, demo_df, oci_df, bapq_df, apdis_df, lsas_df, zbpd_df, sds_df],1)\n",
    "    csv_df.insert(0, 'sub_id', raw_df['prolific_pid'].values)\n",
    "    csv_df.insert(1, 'sub_id_corrected', raw_df['prolific_pid_corrected'].values)\n",
    "    csv_dfs.append(csv_df)\n",
    "    \n",
    "ques_df = pd.concat(csv_dfs)\n",
    "ques_df.reset_index(inplace=True, drop=True)\n",
    "ques_df.to_excel(data_dir + '/Summary/Questionnaire-replication_summary_n' + str(len(ques_df)) + '.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# compute the behavioral geometry            \n",
    "base_dir = main_dir + '/Online/Prolific/Data/Replication_2022'\n",
    "task_files = glob.glob(base_dir + '/Task/Organized/*.xlsx')\n",
    "compute_task_variables(base_dir, task_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_dir = main_dir + '/Online/Prolific/Data/Replication_2022/Summary'\n",
    "post_df = pd.read_excel(glob.glob(summary_dir + '/Posttask*')[0])\n",
    "task_df = pd.read_excel(glob.glob(summary_dir + '/SNT*')[0])\n",
    "survey_df = pd.read_excel(glob.glob(summary_dir + '/Questionnaire*')[0])\n",
    "corrected = survey_df['sub_id_corrected'].values.astype(str)\n",
    "for c, corr in enumerate(corrected):\n",
    "    if corr != 'nan': survey_df['sub_id'][c] = corr.strip()\n",
    "\n",
    "# find overlap\n",
    "task_subs = task_df['sub_id'].values\n",
    "post_subs = post_df['sub_id'].values\n",
    "survey_subs = survey_df['sub_id'].values\n",
    "\n",
    "overlap = list(set(survey_subs) & set(task_subs) & set(post_subs))\n",
    "sub_dfs = []\n",
    "for sub in overlap:\n",
    "    \n",
    "    task_ix = np.where(task_subs == sub)[0][0]\n",
    "    post_ix = np.where(post_subs == sub)[0][0]\n",
    "    survey_ix = np.where(survey_subs == sub)[0][0]\n",
    "    sub_data = np.concatenate((task_df.iloc[task_ix, 1:], \n",
    "                               post_df.iloc[post_ix, 1:], \n",
    "                               survey_df.iloc[survey_ix, 1:])).reshape(1,-1)                      \n",
    "    colnames = np.concatenate((task_df.iloc[:, 1:].columns.values, \n",
    "                               post_df.iloc[:, 1:].columns.values, \n",
    "                               survey_df.iloc[:, 1:].columns.values))\n",
    "    sub_dfs.append(pd.DataFrame(sub_data, columns=colnames)) \n",
    "    \n",
    "data_df = pd.concat(sub_dfs)\n",
    "data_df.insert(0, 'sub_id', overlap)\n",
    "data_df['demo_employed'] = ((data_df['demo_occupation']!=8) & (data_df['demo_occupation']!=9)) * 1    \n",
    "data_df.to_excel(data_dir + '/Summary/All-data-replication_summary_n' + str(len(data_df)) + '.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
