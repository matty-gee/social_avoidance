{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, random, math, patsy \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.spatial import distance\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "user = os.path.expanduser('~')\n",
    "sys.path.insert(0, f'{user}/Dropbox/Projects/toolbox/toolbox')\n",
    "from utils import merge_dfs\n",
    "\n",
    "ques_prefixes   = ['oci', 'zbpd', 'sds', 'aes', 'sss', 'lsas_av', 'apdis', 'bapq']\n",
    "all_prefixes    = ['oci', 'zbpd', 'sds', 'aes', 'sss', 'lsas_av', 'apdis', 'bapq'] + ['audit', 'aq', 'eat', 'pid5', 'pdi', 'stai_t', 'stai_s', 'pq16', 'pss', 'ucls', 'dtm', 'dtn', 'dtp', 'ucls', 'sh']\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "# convenience functions\n",
    "def subset_df(df, ques_prefixes):\n",
    "\n",
    "    ques_dfs = []\n",
    "    for ques in ques_prefixes: \n",
    "        ques_dfs.append(df.filter(regex=(f\"{ques}_.*\")))\n",
    "    ques_df = pd.concat(ques_dfs, axis=1)\n",
    "    ques_cols = [c for c in ques_df if ('_att' not in c) & ('score' not in c)]\n",
    "    ques_df = ques_df[ques_cols]\n",
    "    ques_df.insert(0, 'sub_id', df['sub_id'])\n",
    "    return ques_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load & clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = f'{user}/Desktop/SNT_data/SNT-online_behavioral/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial raw n=706\n",
      "RT normal: n=670\n",
      "memory thresh: n=665\n",
      "dots worked: n=613\n",
      "questinnaires: n=613\n"
     ]
    }
   ],
   "source": [
    "# initial sample\n",
    "init_dir = f'{main_dir}/Initial_2021/Summary/Individual_summaries'\n",
    "\n",
    "# merge dfs\n",
    "beh_fname  = glob.glob(f'{init_dir}/SNT-behavior_n*')[0]\n",
    "post_fname = glob.glob(f'{init_dir}/SNT-posttask_n*')[0]\n",
    "ques_fname = glob.glob(f'{init_dir}/Questionnaire_summary_n*')[0]\n",
    "df_list = [beh_fname, post_fname, ques_fname]\n",
    "init_df = merge_dfs([pd.read_excel(x) for x in df_list])\n",
    "init_df.insert(1, 'sample', 0)\n",
    "print(f'Initial raw n={len(init_df)}')\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# rt normal\n",
    "#------------------------------------------------------------------------\n",
    "rt_mask_low = init_df['reaction_time_mean'] > 2\n",
    "rt_mask_hi  = init_df['reaction_time_mean'] < 15\n",
    "rt_mask     = rt_mask_low & rt_mask_hi\n",
    "init_df     = init_df[rt_mask]\n",
    "print(f'RT normal: n={len(init_df)}')\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# memory above threshold\n",
    "#------------------------------------------------------------------------\n",
    "init_df = init_df[init_df['memory_mean'] > .20]\n",
    "print(f'memory thresh: n={len(init_df)}')\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# dots working\n",
    "#------------------------------------------------------------------------\n",
    "dots = init_df[['first_dots_affil','second_dots_affil','assistant_dots_affil','powerful_dots_affil','boss_dots_affil']]\n",
    "dots_mask = (np.sum(dots == -.92, 1) != 5) & np.isfinite(init_df['first_dots_affil'])\n",
    "init_df = init_df[dots_mask]\n",
    "print(f'dots worked: n={len(init_df)}')\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# attention checks - TODO\n",
    "#------------------------------------------------------------------------\n",
    "# [c for c in init_df.columns if 'att' in c]\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# questionnaires basically complete\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "ques_mask = np.isfinite(init_df['lsas_av_score'])\n",
    "init_df   = init_df[ques_mask]\n",
    "print(f'questinnaires: n={len(init_df)}')\n",
    "\n",
    "init_df.reset_index(inplace=True, drop=True)\n",
    "init_df.to_excel(f'{init_dir}/../All-data_summary_n{len(init_df)}_clean.xlsx', index=False)\n",
    "\n",
    "# # to run hetcor\n",
    "# init_ques_df = subset_df(init_df, all_prefixes)\n",
    "# init_ques_df.to_csv(f'{init_dir}/Questionnaire_items_n{len(init_df)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial raw n=286\n",
      "RT normal: n=270\n",
      "memory thresh: n=270\n",
      "dots worked: n=266\n",
      "questinnaires: n=264\n"
     ]
    }
   ],
   "source": [
    "# replication sample\n",
    "repl_dir   = f'{main_dir}/Replication_2022/Summary/Individual_summaries'\n",
    "\n",
    "# merge dfs\n",
    "beh_fname  = glob.glob(f'{repl_dir}/SNT-behavior_n*')[0]\n",
    "post_fname = glob.glob(f'{repl_dir}/SNT-posttask_n*')[0]\n",
    "ques_fname = glob.glob(f'{repl_dir}/Questionnaire_summary_n*')[0]\n",
    "df_list = [beh_fname, post_fname, ques_fname]\n",
    "repl_df = merge_dfs([pd.read_excel(x) for x in df_list])\n",
    "repl_df.insert(1, 'sample', 1)\n",
    "print(f'Initial raw n={len(repl_df)}')\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# rt normal\n",
    "#------------------------------------------------------------------------\n",
    "rt_mask_low = repl_df['reaction_time_mean'] > 2\n",
    "rt_mask_hi  = repl_df['reaction_time_mean'] < 15\n",
    "rt_mask     = rt_mask_low & rt_mask_hi\n",
    "repl_df     = repl_df[rt_mask]\n",
    "print(f'RT normal: n={len(repl_df)}')\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# memory above threshold\n",
    "#------------------------------------------------------------------------\n",
    "repl_df = repl_df[repl_df['memory_mean'] > .20]\n",
    "print(f'memory thresh: n={len(repl_df)}')\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# dots working\n",
    "#------------------------------------------------------------------------\n",
    "dots = repl_df[['first_dots_affil','second_dots_affil','assistant_dots_affil','powerful_dots_affil','boss_dots_affil']]\n",
    "dots_mask = (np.sum(dots == -.92, 1) != 5) & np.isfinite(repl_df['first_dots_affil'])\n",
    "repl_df = repl_df[dots_mask]\n",
    "print(f'dots worked: n={len(repl_df)}')\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# questionnaires\n",
    "#------------------------------------------------------------------------\n",
    "ques_mask = np.isfinite(repl_df['lsas_av_score'])\n",
    "repl_df = repl_df[ques_mask]\n",
    "print(f'questinnaires: n={len(repl_df)}')\n",
    "\n",
    "repl_df.reset_index(inplace=True, drop=True)\n",
    "repl_df.to_excel(f'{repl_dir}/../All-data_summary_n{len(repl_df)}_clean.xlsx', index=False)\n",
    "\n",
    "# # to run hetcor\n",
    "# repl_ques_df = subset_df(repl_df, all_prefixes)\n",
    "# repl_ques_df.to_csv(f'{repl_dir}/Questionnaire_items_n{len(repl_ques_df)}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social_navigation_analysis",
   "language": "python",
   "name": "social_navigation_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
