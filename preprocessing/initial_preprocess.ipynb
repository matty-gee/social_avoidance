{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import glob\n",
    "from datetime import date\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/matty_gee/Desktop/SNT/SNT-behavior/Online/Prolific/Code/0_utilities')\n",
    "# from prolific_behavior_general_utils import *\n",
    "from prolific_generic_utils import *\n",
    "\n",
    "# info about the validated decisions: e.g., the continuous ratings etc..\n",
    "decisions_info = pd.read_excel('/Users/matty_gee/Desktop/SNT/SNT-Behavior/Online/Prolific/Info/TaskValidation_Val20_SortedOptionMeans_Mem50_n81.xlsx')\n",
    "decisions_info = decisions_info.sort_values(by = 'Decision').reset_index(drop=True)\n",
    "char_roles = ['first', 'second', 'powerful', 'boss', 'assistant', 'neutral'] # order in js...\n",
    "char_role = ['first', 'second', 'powerful', 'boss', 'assistant', 'neutral'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From VT server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir       = '/Users/matty_gee/Desktop/SNT/SNT-behavior/Online/Prolific/Data/Original_2021/Task'\n",
    "sub_files      = [sub_data for sub_data in glob.glob(data_dir + \"/Raw-VT_server/*.json.txt\")]\n",
    "sub_ids        = []\n",
    "dates          = []\n",
    "posttask_dfs   = []\n",
    "browser_list   = []\n",
    "task_responses = []\n",
    "task_versions  = []\n",
    "memory_dfs     = []\n",
    "\n",
    "\n",
    "for file in sub_files:\n",
    "    with open(file) as f:\n",
    "        \n",
    "        # get data\n",
    "        data = json.load(f)\n",
    "        if ('preview=1' not in data['metadata']['url']) and ('prolific_pid' in data['metadata']['social_task_data']): # exclude previews/tests\n",
    "            \n",
    "            exp_data = data['metadata']['social_task_data']\n",
    "            sub_id = exp_data['prolific_pid']\n",
    "            sub_ids.append(sub_id)\n",
    "            \n",
    "            date = sub_files[0].split('/')[-1].split('.')[2].split('T')[0]\n",
    "            dates.append(date[0:4] + '-' + date[4:6] + '-' + date[6:])\n",
    "\n",
    "            # check for browser type - dots debugging hppefully....\n",
    "            if 'browser' in data['metadata']:\n",
    "                browser = data['metadata']['browser']\n",
    "            else:\n",
    "                browser = 'unknown'\n",
    "            browser_list.append((exp_data['prolific_pid'], exp_data['session_id'], browser))\n",
    "\n",
    "            ############################################################\n",
    "            # task version, character info\n",
    "            ############################################################\n",
    "\n",
    "            narrative_ver = exp_data['version']\n",
    "            task_versions.append(narrative_ver)\n",
    "            \n",
    "            char_name     = [name for name, img in exp_data['character_imgs'].items()]\n",
    "            char_img      = [img for name, img in exp_data['character_imgs'].items()]\n",
    "\n",
    "            # if the first character is a woman have to reorganize...\n",
    "            female_first = [1,0,2,3,5,4]\n",
    "            if 'F' in narrative_ver:\n",
    "                char_name = [char_name[f] for f in female_first]\n",
    "                char_img = [char_img[f] for f in female_first]\n",
    "\n",
    "            char_gender    = []\n",
    "            char_skincolor = []\n",
    "            for img in char_img: \n",
    "                if 'Br_' in img:\n",
    "                    char_skincolor.append('brown')\n",
    "                else:\n",
    "                    char_skincolor.append('white')\n",
    "                if 'Male' in img:\n",
    "                    char_gender.append('man')\n",
    "                else:\n",
    "                    char_gender.append('woman')\n",
    "\n",
    "            ############################################################\n",
    "            # narrative task\n",
    "            ############################################################\n",
    "\n",
    "            # get task responses, options order\n",
    "            narrative_resp = exp_data['narrative_resps'][1:-1].split(',')\n",
    "            narrative_resp = list(map(int, narrative_resp)) # turn into integers\n",
    "            narrative_opt_order = exp_data['narrative_opts_order'][1:-1].split('],[')\n",
    "\n",
    "            # standardize & collect responses, depending on alphabetical ordering of options\n",
    "            narrative_resp_data = np.zeros(len(narrative_resp))  \n",
    "            affl_cont = []\n",
    "            pwr_cont  = []\n",
    "            affl_disc = []\n",
    "            pwr_disc  = []\n",
    "            for q, question in enumerate(narrative_opt_order):\n",
    "\n",
    "                # get response, accounting for option randomization \n",
    "                opt1 = remove_nontext(question.split('\",\"')[0])\n",
    "                opt2 = remove_nontext(question.split('\",\"')[1])\n",
    "                sort_ix = np.argsort((opt1,opt2)) # order options alphabetically\n",
    "                resp = sort_ix[narrative_resp[q]-1]+1 # choice -> 1 or 2, depending on alphabetical ordering\n",
    "                narrative_resp_data[q] = resp\n",
    "\n",
    "                # turn response into the validated ratings\n",
    "                decision = decisions_info.iloc[q]\n",
    "                affl_cont.append(decision['Opt{}_Affl_Mean'.format(int(resp))])\n",
    "                pwr_cont.append(decision['Opt{}_Pwr_Mean'.format(int(resp))])\n",
    "                affl_disc.append(decision['Opt{}_Affl_Discrete'.format(int(resp))])\n",
    "                pwr_disc.append(decision['Opt{}_Pwr_Discrete'.format(int(resp))])\n",
    "\n",
    "            # all_responses\n",
    "            task_responses.append(np.array(pwr_disc) + np.array(affl_disc))\n",
    "            \n",
    "            # get rts \n",
    "            narrative_rts = np.array([int(i, base=16) for i in exp_data['narrative_rts'][1:-1].split(',')])\n",
    "            decision_rts  = narrative_rts[np.array(decisions_info['Slide_num'])-1]\n",
    "\n",
    "            ############################################################\n",
    "            # create an output file (will compute geometry in matlab)\n",
    "            ############################################################\n",
    "\n",
    "            narrative_df = pd.DataFrame((narrative_resp, affl_disc, pwr_disc, decision_rts)).T\n",
    "            narrative_df.columns = ['button_press','affil', 'power', 'rt']\n",
    "            narrative_df.insert(0, 'trial_num', np.arange(1,64))\n",
    "            narrative_df.to_excel(data_dir + '/Organized/SNT_' + sub_id + '.xlsx', index=False)\n",
    "\n",
    "            ############################################################\n",
    "            # memory task\n",
    "            ############################################################\n",
    "\n",
    "            # sort question/response alphabetically\n",
    "            mem_resp = [remove_nontext(x) for x in exp_data['memory_resps'][1:-1].split(',')]\n",
    "            mem_ques = [remove_nontext(x) for x in exp_data['memory_quests_order'][1:-1].split(',')]\n",
    "            mem_data = sorted(list(zip(mem_ques, mem_resp)))\n",
    "\n",
    "            # evaluate responses for which role it corresponds to and if that is correct \n",
    "            # 1 = first, 2 = second, 3 = newcomb, 4 = hayworth, 5 = assistant, 6 = neutral\n",
    "            mem_correct = [1,3,5,3,5,0,0,0,3,1,2,2,1,3,5,2,1,0,4,5,5,4,4,4,2,2,0,1,4,3] # according to the order of characters in char_role\n",
    "            mem_questions = ['mem' + str(q+1) + '_'  + char_role[r] for q,r in enumerate(mem_correct)]\n",
    "            mem_summary = np.zeros(6) # summary % by character...\n",
    "            mem_responses = []\n",
    "            for r,resp in enumerate(mem_data): \n",
    "                mem_responses.append(char_role[char_name.index(resp[1])]) # find the role of the character response\n",
    "                if resp[1] == char_name[mem_correct[r]]: mem_summary[mem_correct[r]]+=1 # if correct \n",
    "            memory_df = pd.DataFrame(mem_summary/5, columns=['memory'])\n",
    "            memory_dfs.append(pd.DataFrame(np.array(mem_responses).reshape(1,-1), columns=mem_questions)) \n",
    "\n",
    "            ############################################################\n",
    "            # dots task \n",
    "            ############################################################\n",
    "\n",
    "            characters_split = exp_data['dots_resps'].split('],[')\n",
    "            dots_data = np.zeros((6,3)) # affil, pwr, duration\n",
    "\n",
    "            for c, character in enumerate(characters_split):\n",
    "\n",
    "                character_data = character.split(',') \n",
    "                character_name = remove_nontext(character_data[0].split(':')[0])\n",
    "                character_img  = character_data[0].split(':')[1].split('.png')[0]\n",
    "\n",
    "                # can simplify this below:\n",
    "                role_id = char_img.index(character_img) \n",
    "                dots_data[role_id,0] = character_data[1].split(':')[1] # affiliation\n",
    "                dots_data[role_id,1] = character_data[2].split(':')[1] # power\n",
    "                dots_data[role_id,2] = remove_nontext(character_data[3].split(':')[1]) # duration\n",
    "\n",
    "            dots_df = pd.DataFrame(dots_data, columns=['dots_affil', 'dots_power', 'duration(ms)'])\n",
    "\n",
    "            ############################################################\n",
    "            # perception tasks\n",
    "            ############################################################\n",
    "\n",
    "            perception_tasks = ['liking','competence','similarity']\n",
    "            perception_resps = np.zeros((6,len(perception_tasks)))\n",
    "            perception_rts   = np.zeros((6,len(perception_tasks)))\n",
    "            for t,task in enumerate(perception_tasks):\n",
    "                perception_resps[:,t] = np.array(list(map(int, exp_data[task + '_resps'][1:-1].split(','))))\n",
    "                perception_rts[:,t]   = list(map(int, exp_data[task + '_rts'][1:-1].split(',')))\n",
    "\n",
    "            ############################################################\n",
    "            # emotion tasks\n",
    "            ############################################################\n",
    "\n",
    "            emot_dims = ['\"arousal\"','\"valence\"','\"stability\"']\n",
    "            ratings = np.zeros((6,len(emot_dims)))\n",
    "\n",
    "            # will be same character order as other perception tasks\n",
    "            for r, resps in enumerate(exp_data['emotion_resps'].split('],')):\n",
    "                resps    = resps.replace('[', \"\").replace(']', \"\") # annoying way to do this...\n",
    "                dims     = [r for r in resps.split(',')[::2]] # get the order of the dims in task\n",
    "                dims_ixs = np.array([dims.index(dim) for dim in emot_dims]) # turn into ixs, based on my order\n",
    "                ratings[r,:]  = np.array([int(r) for r in resps.split(',')[1::2]])[dims_ixs] # get & order ratings\n",
    "\n",
    "            # gather + sort by the role order (based on image order) (character X task)\n",
    "            perception_resps = np.concatenate((perception_resps, ratings),axis=1)\n",
    "            role_sorting     = np.array([exp_data['perception_character_order'].index(char) for char in char_name])\n",
    "            perception_data  = perception_resps[role_sorting]\n",
    "            perception_df    = pd.DataFrame(perception_data, columns=['liking','competence','similarity','arousal','valence','stability'])\n",
    "\n",
    "            ############################################################\n",
    "            # output perception \n",
    "            ############################################################        \n",
    "\n",
    "            # per subject\n",
    "            perc_mem_df = pd.concat([memory_df, dots_df, perception_df], axis=1)\n",
    "            perc_mem_df.insert(0, 'task_version', narrative_ver)\n",
    "            perc_mem_df.insert(1, 'name', np.array(char_name))\n",
    "            perc_mem_df.insert(2, 'gender', np.array(char_gender))\n",
    "            perc_mem_df.insert(3, 'skincolor', np.array(char_skincolor))\n",
    "            perc_mem_df.insert(4, 'image', char_img)\n",
    "#             perc_mem_df.to_excel(data_dir + '/Organized/' + sub_id + '_posttask_data.xlsx', index=False)\n",
    "\n",
    "            # for summary sheet\n",
    "            perc_mem_flattened = []\n",
    "            perc_mem_cols = []\n",
    "            for r,row in enumerate(perc_mem_df.iterrows()):\n",
    "                perc_mem_flattened.extend([row[1][col] for col in perc_mem_df.columns])\n",
    "                perc_mem_cols.extend([char_role[r]+'_'+col for col in perc_mem_df.columns])\n",
    "                \n",
    "            perc_mem_flattened_df = pd.DataFrame(np.array(perc_mem_flattened).reshape(1,-1), columns=perc_mem_cols)\n",
    "\n",
    "            ############################################################\n",
    "            # iq\n",
    "            ############################################################       \n",
    "\n",
    "            iq_ques = [remove_nontext(ques) for ques in exp_data['iq_quests'][1:-1].split(',')]\n",
    "            iq_resp = [remove_nontext(resp) for resp in exp_data['iq_resps'][1:-1].split(',')]\n",
    "            iq_rt   = exp_data['iq_rts'][1:-1].split(',')\n",
    "            answers =  [[\"VR4\",5],[\"VR16\",\"Its\"],[\"VR17\",47],[\"VR19\",\"Sunday\"],\n",
    "                        [\"LN7\",\"X\"],[\"LN33\",\"G\"],[\"LN34\",\"X\"],[\"LN58\",\"N\"],\n",
    "                        [\"MX45\",\"E\"],[\"MX46\",\"B\"],[\"MX47\",\"B\"],[\"MX55\",\"D\"],\n",
    "                        [\"R3D3\",\"C\"],[\"R3D4\",\"B\"],[\"R3D6\",\"F\"],[\"R3D8\",\"G\"]]\n",
    "            iq_correct = np.zeros(len(answers))\n",
    "            for answer in answers: \n",
    "                for (q,ques), resp in zip(enumerate(iq_ques), iq_resp):\n",
    "                    if ques == answer[0]:\n",
    "                        if resp == answer[1]:\n",
    "                            iq_correct[q] = 1\n",
    "\n",
    "            ############################################################\n",
    "            # end Qs\n",
    "            ############################################################ \n",
    "\n",
    "            end_questions = exp_data['end_questions'].split(';') #re.findall(r':(\\w+)', exp_data['end_questions']) # this excludes free resp for now\n",
    "            good = [resp for resp in end_questions if 'good:' in resp][0].split(':')[1]\n",
    "            bad = [resp for resp in end_questions if 'bad:' in resp][0].split(':')[1]\n",
    "            engagement = [resp for resp in end_questions if 'engagement:' in resp][0].split(':')[1]\n",
    "            difficulty = [resp for resp in end_questions if 'difficulty:' in resp][0].split(':')[1]\n",
    "            relatability = [resp for resp in end_questions if 'relatability:' in resp][0].split(':')[1]\n",
    "            end_resps  = np.array([good, bad, int(engagement), int(difficulty), int(remove_nontext(relatability))])\n",
    "\n",
    "            ############################################################\n",
    "            # organize all post-task\n",
    "            ############################################################\n",
    "\n",
    "            colnames = np.concatenate((perc_mem_cols, ['mean_memory','mean_liking','mean_competence','mean_similarity','mean_arousal','mean_valence','mean_stability'], np.array(['iq_' + a[0] for a in answers]), ['iq_score', 'end_good','end_bad','end_engagement','end_difficulty','end_relatability']))\n",
    "            sub_data = np.concatenate((perc_mem_flattened, np.array([np.mean(mem_summary/5)]), np.mean(perception_data,axis=1), iq_correct, np.array([np.mean(iq_correct)]), end_resps)).reshape(1,-1)\n",
    "            posttask_dfs.append(pd.DataFrame(sub_data, columns = colnames))\n",
    "\n",
    "\n",
    "out_dir = '/Users/matty_gee/Desktop/SNT/SNT-behavior/Online/Prolific/Data/Original_2021/'\n",
    "\n",
    "# ############################################################\n",
    "# # task decisions\n",
    "# ############################################################ \n",
    "\n",
    "# task_responses_df = pd.DataFrame(task_responses, columns=['decision_' + '{:02d}'.format(n) for n in np.arange(1,64)])\n",
    "# task_responses_df.insert(0, 'sub_id', np.array(sub_ids))\n",
    "# task_responses_df.insert(1, 'task_version', task_versions)\n",
    "# task_responses_df.to_excel(out_dir + '/Prolific_task_responses_n' + str(len(sub_ids)) + '.xlsx', index=False)\n",
    "\n",
    "############################################################\n",
    "# posttask summary\n",
    "############################################################    \n",
    "\n",
    "posttask_df_summary = pd.concat([pd.concat(posttask_dfs), pd.concat(memory_dfs)], axis=1)\n",
    "posttask_df_summary.insert(0, 'sub_id', np.array(sub_ids))\n",
    "posttask_df_summary.insert(1, 'task_version', task_versions)\n",
    "posttask_df_summary.insert(2, 'date', dates)\n",
    "posttask_df_summary.to_excel(out_dir + '/Posttask-original-VT_summary_n' + str(len(sub_ids)) + '.xlsx', index=False)\n",
    "\n",
    "# pd.DataFrame(browser_list, columns = ['sub_id', 'sess_id', 'browser']).to_excel(out_dir + '/Prolific_completed_list_n' + str(len(sub_ids)) + '.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From pavlovia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = first, 2 = second, 3 = newcomb, 4 = hayworth, 5 = assistant, 6 = neutral\n",
    "def get_memory(data, char_names):\n",
    "    \n",
    "    try:\n",
    "        memory_data = data['memory_resps'].values[0]\n",
    "    except: \n",
    "        memory_data = data['character_memory'].values[0]\n",
    "\n",
    "    memory = [ques.split(';')[1:2] for ques in memory_data.split('\",\"')]\n",
    "    mem_ques = [mem[0].split(':')[0] for mem in memory]\n",
    "    mem_resp = [mem[0].split(':')[1] for mem in memory]\n",
    "\n",
    "    mem_data = sorted(list(zip(mem_ques, mem_resp)))\n",
    "\n",
    "    # 1 = first, 2 = second, 3 = newcomb, 4 = hayworth, 5 = assistant, 6 = neutral\n",
    "    mem_correct = [1,3,5,3,5,0,0,0,3,1,2,2,1,3,5,2,1,0,4,5,5,4,4,4,2,2,0,1,4,3]# according to the order of characters in char_role\n",
    "    mem_acc = np.zeros(6) # organize by character...\n",
    "    for r,resp in enumerate(mem_data): \n",
    "        if resp[1] == char_names[mem_correct[r]]:\n",
    "            mem_acc[mem_correct[r]]+=1\n",
    "    mem_acc_df = pd.DataFrame((mem_acc/5).reshape(1,-1), columns=[char + '_memory' for char in char_roles])\n",
    "    mem_acc_df.insert(6, 'mean_memory', np.mean(mem_acc_df.values))\n",
    "\n",
    "    # also output the response\n",
    "    mem_questions = ['mem' + str(q+1) + '_'  + char_roles[r] for q,r in enumerate(mem_correct)]\n",
    "    mem_responses = [char_roles[char_names.index(resp[1])] for r,resp in enumerate(mem_data)] # find the role of the character response\n",
    "    mem_resp_df = pd.DataFrame(np.array(mem_responses).reshape(1,-1), columns=mem_questions)\n",
    "\n",
    "    return pd.concat([mem_acc_df, mem_resp_df], axis=1) \n",
    "\n",
    "# dumb to have different orders everywhere...should just be explicit...\n",
    "img_sets = {'OFA': ['OlderFemaleBl_2','OlderMaleW_1','OlderMaleW_4','OlderFemaleBr_3','OlderMaleBr_2','OlderFemaleW_1'],\n",
    "            'OFB': ['OlderFemaleW_2','OlderMaleBr_1','OlderMaleBl_3','OlderFemaleW_3','OlderMaleW_5','OlderFemaleBl_1'],\n",
    "            'OFC': ['OlderFemaleBl_2','OlderMaleBr_1','OlderMaleW_5','OlderFemaleW_3','OlderMaleBr_4','OlderFemaleW_1'],\n",
    "            'OFD': ['OlderFemaleW_2','OlderMaleW_1','OlderMaleBr_3','OlderFemaleBr_3','OlderMaleW_5','OlderFemaleBl_1'],\n",
    "            'OMA': ['OlderMaleBr_2','OlderFemaleW_2','OlderFemaleW_3','OlderMaleBr_1','OlderFemaleBr_5','OlderMaleW_5'],\n",
    "            'OMB': ['OlderMaleW_1','OlderFemaleBl_2','OlderFemaleBl_3','OlderMaleW_4','OlderFemaleW_1','OlderMaleBr_4'], \n",
    "            'OMC': ['OlderMaleBr_4','OlderFemaleBl_2','OlderFemaleW_3','OlderMaleW_3','OlderFemaleBl_1','OlderMaleW_5'],\n",
    "            'OMD': ['OlderMaleW_1','OlderFemaleW_2','OlderFemaleBr_5','OlderMaleBr_3','OlderFemaleW_1','OlderMaleBr_4'],\n",
    "            'YFA': ['YoungerFemaleBr_1','YoungerMaleW_4','YoungerMaleW_3','OlderFemaleBr_5','OlderMaleBr_4','OlderFemaleW_1'],\n",
    "            'YFB': ['YoungerFemaleW_3','YoungerMaleBr_2','OlderMaleBr_3','OlderFemaleW_4','YoungerMaleW_2','OlderFemaleBl_1'],\n",
    "            'YFC': ['YoungerFemaleBr_1','YoungerMaleBr_2','OlderMaleW_4','OlderFemaleW_3','OlderMaleBr_4','OlderFemaleW_1'],\n",
    "            'YFD': ['YoungerFemaleW_3','YoungerMaleW_4','OlderMaleBr_3','OlderFemaleBr_5','OlderMaleW_5','OlderFemaleBl_1'],\n",
    "            'YMA': ['YoungerMaleBr_2','YoungerFemaleW_3','OlderFemaleW_4','OlderMaleBr_3','OlderFemaleBl_1','YoungerMaleW_2'],\n",
    "            'YMB': ['YoungerMaleW_4','YoungerFemaleBr_1','OlderFemaleBr_5','YoungerMaleW_3','OlderFemaleW_1','OlderMaleBr_4'],\n",
    "            'YMC': ['YoungerMaleBr_2','YoungerFemaleBr_1','OlderFemaleW_3','OlderMaleW_3','OlderFemaleBl_1','OlderMaleW_5'],\n",
    "            'YMD': ['YoungerMaleW_4','YoungerFemaleW_3','OlderFemaleBr_3','OlderMaleBr_3','OlderFemaleW_1','OlderMaleBr_4']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/matty_gee/Desktop/SNT/SNT-behavior/Online/Prolific/Data/Original_2021'\n",
    "sub_files = [sub_data for sub_data in glob.glob(data_dir + \"/Task/Raw-Pavlovia/*.csv\")]\n",
    "task_vers = []\n",
    "dates     = []\n",
    "posttask_dfs = []\n",
    "for file in sub_files:\n",
    "    \n",
    "    data = pd.read_csv(file)\n",
    "    sub_id = data['prolific_id'].values[0]\n",
    "    if sub_id not in ['5fb28e64134ec0894396633a', '60393e9ddde61e3a5463746d']:\n",
    "\n",
    "        #################################################################\n",
    "        # task version info\n",
    "        #################################################################\n",
    "        \n",
    "        task_ver = data['task_ver'].values[0]\n",
    "        task_vers.append(task_ver)\n",
    "        \n",
    "        date = file.split('/')[-1].split('_')[3]\n",
    "        dates.append(date)\n",
    "        \n",
    "        # character names  \n",
    "        char_imgs = img_sets[task_ver]\n",
    "        if 'Male' in char_imgs[0]:\n",
    "            char_names = ['Chris','Maya','Newcomb','Hayworth','Kayce','Anthony']\n",
    "        else:\n",
    "            char_names = ['Maya','Chris','Newcomb','Hayworth','Anthony','Kayce']\n",
    "        \n",
    "        # character demographics                    \n",
    "        char_imgs\n",
    "        char_gender    = []\n",
    "        char_skincolor = []\n",
    "        for img in char_imgs: \n",
    "            if 'Br_' in img:\n",
    "                char_skincolor.append('brown')\n",
    "            else:\n",
    "                char_skincolor.append('white')\n",
    "            if 'Male' in img:\n",
    "                char_gender.append('man')\n",
    "            else:\n",
    "                char_gender.append('woman')\n",
    "        gender_df = pd.DataFrame(np.array(char_gender).reshape(1,-1), index=[sub_id], columns=[role + '_gender' for role in char_roles])\n",
    "        skincolor_df = pd.DataFrame(np.array(char_skincolor).reshape(1,-1), index=[sub_id], columns=[role + '_skincolor' for role in char_roles])\n",
    "\n",
    "        #################################################################\n",
    "        # narrative decisions\n",
    "        #################################################################\n",
    "        \n",
    "        # narrative responses  \n",
    "        try: # changed the name at some point\n",
    "            narrative_resp = np.array([int(re.sub('[\"\\]\"]', '', d.split(':')[1])) for d in data['narrative_choices'].values[0].split(',')])\n",
    "        except:\n",
    "            narrative_resp = np.array([int(re.sub('[\"\\]\"]', '', d.split(':')[1])) for d in data['narrative_resps'].values[0].split(',')])\n",
    "\n",
    "        narrative_opt_order = data['narrative_opts_order'].values[0].split('\",\"')\n",
    "        narrative_resp_data = np.zeros(len(narrative_resp))\n",
    "        affl = []\n",
    "        pwr  = []\n",
    "        for q, question in enumerate(narrative_opt_order):\n",
    "            # reallllyyyy did this dumb...\n",
    "            question = ''.join(filter(lambda item: not item.isdigit(), question))\n",
    "            if ';' in question:\n",
    "                opt1 = remove_nontext(question.split(';')[1])\n",
    "                opt2 = remove_nontext(question.split(';')[2])\n",
    "            elif ',\"' in question:\n",
    "                opt1 = remove_nontext(question.split(',\"')[0])\n",
    "                opt2 = remove_nontext(question.split(',\"')[1]) \n",
    "            elif '.,' in question:\n",
    "                opt1 = remove_nontext(question.split('.,')[0])\n",
    "                opt2 = remove_nontext(question.split('.,')[1]) \n",
    "                \n",
    "            sort_ix = np.argsort((opt1,opt2)) # order options alphabetically\n",
    "            resp = sort_ix[narrative_resp[q]-1]+1 # choice -> 1 or 2, depending on alphabetical ordering\n",
    "            narrative_resp_data[q] = resp\n",
    "            decision = decisions_info.iloc[q]\n",
    "            affl.append(decision['Opt{}_Affl_Discrete'.format(int(resp))])\n",
    "            pwr.append(decision['Opt{}_Pwr_Discrete'.format(int(resp))])\n",
    "        narrative_rts = np.array([int(remove_nontext(rt)) for rt in data['narrative_rts'].values[0].split(',')])\n",
    "        decision_rts  = narrative_rts[np.array(decisions_info['Slide_num'])-1]\n",
    "        narrative_df = pd.DataFrame((narrative_resp, affl, pwr, decision_rts)).T\n",
    "        narrative_df.columns = ['button_press', 'affil', 'power', 'rt']\n",
    "        narrative_df.insert(0, 'trial_num', np.arange(1,64))\n",
    "        narrative_df.to_excel(data_dir + '/Task/Organized/SNT_' + sub_id + '.xlsx', index=False)\n",
    "        \n",
    "        ######################################################################\n",
    "        # POST TASK \n",
    "        ######################################################################\n",
    "        \n",
    "        # memory\n",
    "        memory_df = get_memory(data, char_names)\n",
    "        memory_df.index = [sub_id]\n",
    "        \n",
    "        # dots \n",
    "        dots_df = pd.DataFrame(index=[sub_id], columns=[char + '_dots_' + dim for char in char_roles for dim in ['affil','power']])\n",
    "        for row in data['dots_resps'].values[0].split(','):\n",
    "            row_split = row.split(';')\n",
    "            role = char_roles[char_names.index(remove_nontext(row_split[0].split(':')[0]))]\n",
    "            dots_df[role + '_dots_affil'] = float(row_split[1].split(':')[1])\n",
    "            dots_df[role + '_dots_power'] = float(row_split[2].split(':')[1])\n",
    "\n",
    "        # relationship evaluations\n",
    "        try:\n",
    "            character_relationship = [char.split(';') for char in data['character_relationship'].values[0].split(',')]\n",
    "        except: \n",
    "            character_relationship = [char.split(';') for char in data['relationship_feelings'].values[0].split(',')]\n",
    "            \n",
    "        rel_df = pd.DataFrame(index=[sub_id], columns=[char + '_' + rel for char in char_roles for rel in ['arousal','valence','stability']])\n",
    "        for char in character_relationship:\n",
    "            role = char_roles[char_names.index(remove_nontext(char[0]))]\n",
    "            for r in range(1,4):\n",
    "                rel = char[r].split(':')[0]\n",
    "                rating = float(char[r].split(':')[1])\n",
    "                rel_df[role + '_' + rel] = rating\n",
    "        for dim in ['arousal','valence','stability']:\n",
    "            rel_df['mean_' + dim] = np.mean(rel_df[[char + '_' + dim for char in char_roles]].values)\n",
    "\n",
    "        # character evaluations    \n",
    "        dims = ['status', 'competence', 'youthful', 'gender', 'similarity', 'approachable', 'dominant', 'likability', 'trustworthy', 'race']\n",
    "        try:\n",
    "            resps = [row.split(';') for row in data['character_dimensions'].values[0].split(',')]\n",
    "        except: \n",
    "            resps = [row.split(';') for row in data['character_ratings'].values[0].split(',')]\n",
    "        \n",
    "        dim_df = pd.DataFrame(index=[sub_id], columns=[char + '_' + dim for char in char_roles for dim in dims])\n",
    "        for resp in resps:\n",
    "            name = remove_nontext(resp[0])\n",
    "            if name != 'attention':\n",
    "                role = char_roles[char_names.index(remove_nontext(resp[0]))]\n",
    "                dim_df[role + '_' + resp[1].split(':')[0]] = int(resp[1].split(':')[1])\n",
    "\n",
    "        for dim in ['status', 'competence', 'youthful', 'gender', 'similarity', 'approachable', 'dominant', 'likability', 'trustworthy']:\n",
    "            dim_df['mean_' + dim] = np.mean(dim_df[[char + '_' + dim for char in char_roles]].values)\n",
    "\n",
    "        # add race\n",
    "        try:\n",
    "            char_race = data['character_race'].values[0].split('\",\"')\n",
    "        except:\n",
    "            char_race = data['race_categorization'].values[0].split('\",\"')\n",
    "        for resp in char_race:\n",
    "            role = char_roles[char_names.index(remove_nontext(resp.split(';')[0].split(',')[0]))]\n",
    "            dim_df[role + '_race'] = resp.split(';')[1].split(':')[1]\n",
    "            \n",
    "        posttask_dfs.append(pd.concat([gender_df, skincolor_df, memory_df, dots_df, dim_df, rel_df], axis=1))\n",
    "    \n",
    "posttask_df = pd.concat(posttask_dfs)\n",
    "posttask_df.index.name = 'sub_id'\n",
    "posttask_df.reset_index(inplace=True)\n",
    "posttask_df.insert(1, 'task_version', task_vers)\n",
    "posttask_df.insert(2, 'date', dates)\n",
    "posttask_df.to_excel(data_dir + '/Summary/Posttask-pavlovia_summary_n' + str(len(posttask_df)) + '.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
