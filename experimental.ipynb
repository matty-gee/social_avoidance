{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial n=579\n",
      "Validation n=255\n",
      "Combined n=834\n",
      "Questionnaire items loaded\n"
     ]
    }
   ],
   "source": [
    "from utils_project import *\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def get_item(item):\n",
    "    return questionnaire_items[questionnaire_items['item']==item]\n",
    "\n",
    "# demo_controls = ['demo_age', 'demo_gender_1W', 'demo_race_white', 'iq_score', 'disorder'] \n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "# reverse the sign of power_tendency_mean in data\n",
    "data['power_mean_mean'] = data['power_mean_mean'] * -1\n",
    "sample_dict = update_sample_dict(data)\n",
    "# data[['sub_id', 'sample', 'affil_mean_mean', 'power_mean_mean'] + demo_controls + [f'factor_{f}_quartimax_thresh25' for f in ['social', 'mood', 'compulsive']]].to_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD &/OR EXPERIMENTAL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to infer diff. poss. viewpoints"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance-social factor relationship from all viewpoints\n",
    "- POV we selected is close to best\n",
    "- but also maybe suggests we should assume a participant-by-particiant viewpoint: but how to estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from scipy.optimize import minimize\n",
    "def origin_corr_dist(ori, y, df):\n",
    "    # to minimize the correlation distance to find the best origin\n",
    "    a, p = ori\n",
    "    vecs = []\n",
    "    for char in character_roles[:5]:\n",
    "        ap = np.concatenate((df[f'affil_coord_{char}'].values.reshape(-1,1), \n",
    "                             df[f'power_coord_{char}'].values.reshape(-1,1)), 1)\n",
    "        ap_ref = ap - (a, p)\n",
    "        vecs.append([np.linalg.norm(ap) for ap in ap_ref])\n",
    "\n",
    "    # calculate correlation distance\n",
    "    return 1 - scipy.stats.pearsonr(np.mean(vecs, axis=0), df[y])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the space\n",
    "units = 13 # make odd (13 is regular)\n",
    "space_corrs = np.zeros((units, units))\n",
    "adj = int(units/2 - .5) # readjust back to plot\n",
    "lb, ub = -adj, adj + 1\n",
    "\n",
    "for s, (sample, df) in enumerate(sample_dict.items()):\n",
    "    \n",
    "    # loop over diff. poss. ref. point\n",
    "    vec_refs = pd.DataFrame()\n",
    "    for a_adj, p_adj in itertools.product(np.arange(lb, ub), np.arange(lb, ub)):\n",
    "\n",
    "        # subtract the reference point from each characters coordinates\n",
    "        vecs = []\n",
    "        for role in character_roles[:5]:\n",
    "            ap = np.concatenate((df[f'affil_coord_{role}'].values.reshape(-1,1), \n",
    "                                 df[f'power_coord_{role}'].values.reshape(-1,1)),1)\n",
    "            ap_ref = ap - (a_adj, p_adj) \n",
    "            vecs.append([np.linalg.norm(ap_r) for ap_r in ap_ref])\n",
    "\n",
    "        # calculate correlation\n",
    "        mask = np.isfinite(df[social_factor])\n",
    "        mean_vecs = np.mean(vecs, axis=0)\n",
    "        vec_refs[f'ref_{a_adj}{p_adj}'] = mean_vecs\n",
    "        space_corrs[adj - p_adj, adj + a_adj] = pearsonr(mean_vecs[mask], df[social_factor][mask])[0] # to plot in same space\n",
    "\n",
    "    #-----------------------------------------------------------------------------------\n",
    "    # plot\n",
    "    #-----------------------------------------------------------------------------------\n",
    "    \n",
    "    # space.astype(str) # 0 out uninteresting cells to control annotation (https://stackoverflow.com/questions/60611055/add-annotation-to-specific-cells-in-heatmap)\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    im = plt.imshow(space_corrs, cmap='RdBu_r', zorder=0)\n",
    "    ax.set_xticks(np.arange(0, units, 1))\n",
    "    ax.set_yticks(np.arange(0, units, 1))\n",
    "    ax.set_yticklabels(reversed(np.arange(lb, ub)))\n",
    "    ax.set_xticklabels(np.arange(lb, ub))\n",
    "    ax.set_xlabel('Affiliation', fontsize=20)\n",
    "    ax.set_ylabel('Power', fontsize=20)\n",
    "    \n",
    "    # add a colorbar\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    cbar = fig.colorbar(im, cax=cax, orientation='vertical')    \n",
    "    cbar.ax.tick_params(labelsize=8) \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    #     # add first eigenvector\n",
    "    #     eig_vals, eig_vecs = np.linalg.eigh(space_corrs) # for symmetric matrices\n",
    "    #     sort = np.argsort(eig_vals)[::-1]\n",
    "    #     eig_vals = eig_vals[sort]\n",
    "    #     eig_vecs = eig_vecs[:, sort]\n",
    "    #     origin = [0,0]\n",
    "    #     ax.quiver(*origin, *eig_vecs[0], color=['r'], scale=eig_vals[0], zorder=1)\n",
    "    #     plt.show()\n",
    "\n",
    "    #-----------------------------------------------------------------------------------\n",
    "    # best reference frame coordinates\n",
    "    #-----------------------------------------------------------------------------------\n",
    "\n",
    "    # # - the point at which if distance is measured from, it maximizes the correlation \n",
    "    # best = np.where(space_corrs==np.max(space_corrs)) # best positive correlation\n",
    "    # best_r = -(best[0][0] - adj) # will be power (y)\n",
    "    # best_c = best[1][0] - adj # will be affil (x)\n",
    "    # print(best_c, best_r)\n",
    "\n",
    "    #-----------------------------------------------------------------------------------\n",
    "    # which x,y minimize the correlation distance? (maximize positive correlation)\n",
    "    #-----------------------------------------------------------------------------------\n",
    "        \n",
    "    best_ref = minimize(origin_corr_dist, (0, 0), bounds=([-6,6], [-6,6]), \n",
    "                        args=(social_factor, df[mask]), method='L-BFGS-B').x\n",
    "    print(f'{sample} best ref location = {best_ref}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for factor in factors:\n",
    "    mask = np.isfinite(df[factor])\n",
    "    res = minimize(origin_corr_dist, (0, 0), \n",
    "                    bounds=([-6,6], [-6,6]), \n",
    "                    args=(factor, df[mask]), \n",
    "                    method='L-BFGS-B')\n",
    "    print(f'{factor}: {np.round(res.x, 2)}, r={np.round(1 - res.fun, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orthogonality of affil and power across diff levels of social factor\n",
    "factor_splits = ['lowest', 'low', 'medium', 'high', 'highest']\n",
    "for f_split in factor_splits:\n",
    "    split_data = data[data[f'{social_factor}_split'] == f_split]\n",
    "    r,p = pearsonr(split_data['affil_mean_mean_z'], split_data['power_mean_mean_z'])\n",
    "    print(f'{f_split}: r={r:.3f}, p={p:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual decisions: the specifics of the trajectories..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "from circ_stats import binary_distances\n",
    "\n",
    "def pairwise_annak_distances(ranks):\n",
    "    # https://naturalistic-data.org/content/Intersubject_RSA.html\n",
    "    # anna karenina distance\n",
    "    # metric is mean of ranks, normalized by highest possible rank (n_subs)\n",
    "    n = len(ranks)\n",
    "    annak = np.zeros((n, n))\n",
    "    for i, j in itertools.product(range(n), range(n)):\n",
    "        if i < j:\n",
    "            annak[i,j] = annak[j,i] = np.mean([ranks[i], ranks[j]])/ n\n",
    "        elif i==j:\n",
    "            annak[i,j] = 1\n",
    "    return annak\n",
    "\n",
    "def compute_pairwise(X, pairwise_f): \n",
    "    n = X.shape[1]\n",
    "    out = np.zeros((n, n))\n",
    "    for i in range(0, n):\n",
    "        x1 = X[i,:][:,np.newaxis]\n",
    "        for j in range(i, n):\n",
    "            out[i,j] = out[j, i] = pairwise_f(x1, X[j,:][:,np.newaxis])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_data = data[[c for c in data.columns if 'decision' in c]].values\n",
    "decision_rdm = pairwise_distances(decision_data, metric='hamming')\n",
    "\n",
    "dist_ranks = rankdata(data['pov_2d_dist_mean_mean'].values)\n",
    "sf_ranks   = rankdata(data[social_factor].values)\n",
    "decision_rdm_sorted = sort_symm_mat(decision_rdm, dist_ranks)\n",
    "\n",
    "plot = plot_rdm(sort_symm_mat(decision_rdm, dist_ranks), size=8)\n",
    "plot = plot_rdm(sort_symm_mat(decision_rdm, sf_ranks), size=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dots: can we use neutral character's offset from (0,0) to infer social avoidance?\n",
    "- if yes: suggests high SA ppl might represent others as distant even when there were no affiliation and power interactions\n",
    "- if no: suggests affiliation and power interactions are required\n",
    "\n",
    "neither should be considered strong evidence... \n",
    "\n",
    "Doesnt seem like it affects much here... suggesting (I guess) that decisions are important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['beh_dots_affil_diff_neutral', 'beh_dots_power_diff_neutral', 'dots_pov_dist_neutral']\n",
    "fig, axs = plt.subplots(1, len(cols), figsize=(len(cols)*4, 4), sharey=True)\n",
    "for s, sample in enumerate(['Initial', 'Replication']):\n",
    "    df = sample_dict[sample]\n",
    "    for c, col in enumerate(cols):\n",
    "        ax = axs[c]\n",
    "        sns.regplot(x=df[col], y=df[social_factor], color=sample_colors[s], ax=ax)\n",
    "        # ols_obj = run_ols([col], social_factor, df, covariates=['demo_age', 'demo_sex_1F', 'demo_race_white', 'iq_score'])[1]\n",
    "        # p = ols_obj.pvalues[col] / 2\n",
    "        # print(f'{sample} p={p:3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating the use of factor analysis: regressions w/ individual questionnaires"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS\n",
    "- each questionnaire individually\n",
    "- questionnaires together\n",
    "    - also: select questionnaires on first dataset, then replicate relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_item_labels(ques_prefix):\n",
    "    return [c for c in data.columns if (c.split('_')[0] == ques_prefix) & ('score' not in c) & ('_att' not in c)]\n",
    "\n",
    "# put togehter int a dictionary\n",
    "behs = ['affil_mean_mean_z', 'power_mean_mean_z', 'pov_2d_dist_mean_mean_z']\n",
    "ques = ['oci_score', 'sds_score', 'aes_score', 'sss_score', 'lsas_av_score', 'apdis_score', 'zbpd_score', 'bapq_score']\n",
    "for q in ques: data[f'{q}_z'] = zscore_masked(data[q].values) # zscore the questionnaire scores\n",
    "sample_dict = reset_sample_dict(data)\n",
    "ques_scores = [f'{q}_z' for q in ques]\n",
    "\n",
    "ques_prefix = [q.split('_')[0] for q in ques]\n",
    "ques_dict   = {'scores': ques_scores, 'items': flatten_lists([get_item_labels(qp) for qp in ques_prefix])}\n",
    "\n",
    "# run ols\n",
    "ols_df = pd.DataFrame(columns=['sample', 'predictor_type', 'self-report', 'behavior', 'beta', 'p'])\n",
    "for sample in ['Initial', 'Replication', 'Combined']:\n",
    "    df = sample_dict[sample]\n",
    "    for b in behs:  \n",
    "        for qtype, qs in ques_dict.items():\n",
    "            \n",
    "            # behavior ~ single score/item\n",
    "            for q in qs:\n",
    "                ols = run_ols([q], b, df, covariates=demo_controls)[1]\n",
    "                ols_df.loc[len(ols_df), :] = [sample, f'independent_{qtype}', q, b, ols.params[q], ols.pvalues[q]] \n",
    "\n",
    "            # behavior ~ all scores/items\n",
    "            ols = run_ols(qs, b, df, covariates=demo_controls)[1]\n",
    "            for q in qs:\n",
    "                ols_df.loc[len(ols_df), :] = [sample, f'combined_{qtype}', q, b, ols.params[q], ols.pvalues[q]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many items are reverse scored, so these should all be: higher value means more symptom\n",
    "item_df = ols_df[(ols_df['sample'] == 'Initial') \n",
    "                 & (ols_df['predictor_type'] == 'combined_items') \n",
    "                 & (ols_df['behavior'] == 'pov_2d_dist_mean_mean_z')]\n",
    "item_df.sort_values(by=['sample','p'], inplace=True)\n",
    "item_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# find top items\n",
    "item_df_ = item_df.iloc[:10]\n",
    "for qp in ques_prefix: \n",
    "    items = item_df_[item_df_['self-report'].str.contains(qp)]['self-report']\n",
    "    print(f'{qp}: {items.values}')\n",
    "\n",
    "# find the text\n",
    "for i, item in enumerate(item_df['self-report']):\n",
    "    try: \n",
    "        item_text = questionnaire_items[questionnaire_items['item'] == item]['text'].values[0]\n",
    "        item_df.loc[i, 'item_text'] = item_text\n",
    "    except: \n",
    "        item_df.loc[i, 'item_text'] = 'missing'\n",
    "item_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_weights(weights, colors, title, ax):\n",
    "    weights = weights.astype(float)\n",
    "    w_max = np.round(np.max(np.abs(weights)), 1)\n",
    "    ax.bar(np.arange(len(weights)), weights, color=colors, edgecolor='black', linewidth=0.5)\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    #ax.set_ylim(-w_max-(0.005*w_max), w_max+(0.005*w_max)) \n",
    "\n",
    "behs = ['pov_2d_dist_mean_mean_z']\n",
    "\n",
    "# for plotting\n",
    "colors = ['red', 'blue', 'purple', 'green', 'lavender', 'grey', 'fuchsia', 'orange', 'dodgerblue', \n",
    "          'yellow', 'orchid', 'indigo', 'aqua','palegreen', 'silver', 'plum', 'fuchsia', 'coral',\n",
    "          'gold', 'pink','slategray', 'forestgreen','peachpuff','honeydew','brown','olivedrab',\n",
    "          'darkturquoise', 'tan', 'springgreen', 'mintcream','navajowhite','chocolate','lightblue','chartreuse',\n",
    "          'lime','yellowgreen','khaki','gold','teal','tomato']\n",
    "colors_items = [colors[ques_prefix.index(item.split('_')[0])] for item in ques_items]\n",
    "\n",
    "for sample in ['Combined']:\n",
    "    ols_res = ols_df[ols_df['sample'] == sample]\n",
    "\n",
    "    fig, axs = plt.subplots(len(behs), 3, figsize=(15, 3*len(behs)), gridspec_kw={'width_ratios': [3, 3, 20]})\n",
    "    fig.suptitle(f'{sample} sample', fontsize=18, y=1.01)\n",
    "    if len(behs) == 1:\n",
    "        ax1, ax2, ax3 = axs[0], axs[1], axs[2]\n",
    "    else:\n",
    "        ax1, ax2, ax3 = axs[i,0], axs[i,1], axs[i,2]\n",
    "\n",
    "    for i, beh in enumerate(behs): \n",
    "\n",
    "        # questionnaire ~ behavior\n",
    "        behav = ols_res[(ols_res['predictor_type'] == 'independent') & (ols_res['predicted'] == beh)]\n",
    "        plot_weights(behav['beta'].values, colors, title='Scores independent', ax=ax1)\n",
    "        \n",
    "        # behavior ~ questionnaires\n",
    "        behav = ols_res[(ols_res['predictor_type'] == 'covariate_scores') & (ols_res['predicted'] == beh)]\n",
    "        plot_weights(behav['beta'].values, colors, title='Scores covariates', ax=ax2)\n",
    "        \n",
    "        # behavior ~ questionnaire items\n",
    "        behav = ols_res[(ols_res['predictor_type'] == 'covariate_items') & (ols_res['predicted'] == beh)]\n",
    "        plot_weights(behav['beta'].values, colors_items, title='Items covariates', ax=ax3)\n",
    "\n",
    "    # overall legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    patches = [mpatches.Patch(facecolor=inst[0], edgecolor='black', label=inst[1]) for inst in zip(colors, ques)]  \n",
    "    ax3.legend(title='', loc='upper right', handles=patches,  \n",
    "                    title_fontsize=13, fontsize=8,\n",
    "                    frameon=False, bbox_to_anchor=(1.15, 1), borderaxespad=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personality: agreeableness strongly correlates w/ distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# not intolerance of uncertainty: ['ius_f1','ius_f2']\n",
    "\n",
    "questions = [['mini_ipip_extraversion','mini_ipip_agreeableness','mini_ipip_conscientiousness',\n",
    "              'mini_ipip_neuroticism','mini_ipip_intellect']]\n",
    "for questions_ in questions:\n",
    "\n",
    "    # plot\n",
    "    fig, axs = plt.subplots(1, len(questions_), figsize=(3*len(questions_), 2.5))\n",
    "    for q, ques in enumerate(questions_):\n",
    "        ques_mask = data[ques] != 0.0\n",
    "        sns.regplot(x='pov_2d_dist_mean_mean_z', y=ques, data=data[ques_mask],\n",
    "                    scatter_kws={'alpha':0.3}, color='darkblue',\n",
    "                    ax=axs[q])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # run ols\n",
    "    res_df, _ = run_ols(questions_, 'pov_2d_dist_mean_mean_z', data[ques_mask], covariates=demo_controls)\n",
    "    display(res_df.round(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore new things.... look at tendencies across characters for high social avoidance people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xy_cols = flatten_lists([[f'affil_mean_{role}', f'power_mean_{role}'] for role in character_roles[:5]])\n",
    "# xys = data[xy_cols]\n",
    "\n",
    "# # taking an average might be too simplistic...\n",
    "# # it may be be better to try to capture some kind of curve or something... maybe can use other ratings (e.g., similarity )\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(4,4))\n",
    "\n",
    "# for s in range(10,15):\n",
    "#     xys_ = xys.iloc[s,:].values.reshape(5,2)\n",
    "#     ax.scatter(*xys_.T, s=75, alpha=.5)\n",
    "#     # maybe add some quadratic line or something...\n",
    "#     plot_space_ax(ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brainstorming for modeling....\n",
    "\n",
    "## Deliberation related to RT?\n",
    "- Borderline, schiz related features: fewer symptoms, more rt\n",
    "- self-perceivd status: less status, more rt\n",
    "\n",
    "Can we trust online reaction times? Here, we know that we at least waited until resources were loadeed before prcoeeding... but of course other things can happen... so probably wont do too much here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mask_hi  = data['reaction_time_mean'] < 10\n",
    "mask_low = data['reaction_time_mean'] > 2\n",
    "data_    = data[mask_hi & mask_low]\n",
    "\n",
    "scores = [c for c in data.columns if 'score' in c if 'iq' not in c]\n",
    "for yvar in scores:\n",
    "\n",
    "    ols_obj = run_ols(['reaction_time_mean'], yvar, data_, covariates=demo_controls)[1]\n",
    "    pvalue  = ols_obj.pvalues[1]\n",
    "    if pvalue < 0.01: \n",
    "        fig, axs = plt.subplots(1,2, figsize=(6,3))\n",
    "        sns.histplot(data_['reaction_time_mean'], color='grey', bins=20, ax=axs[0])\n",
    "        sns.regplot(x=data_['reaction_time_mean'], y=data_[yvar], scatter_kws={'alpha':0.2}, color='grey', ax=axs[1])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        display(ols_obj.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset based on social factor percentile and compare top 25% with bottm 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask   = np.isfinite(data[social_factor])\n",
    "data_  = data[mask]\n",
    "bottom = np.percentile(data_[social_factor], 20)\n",
    "top    = np.percentile(data_[social_factor], 80)\n",
    "data['social_factor_bin'] = np.where(data[social_factor] < bottom, 'low', np.where(data[social_factor] > top, 'high', 'middle'))\n",
    "\n",
    "n_low = np.sum(data['social_factor_bin'] == 'low')\n",
    "n_mid = np.sum(data['social_factor_bin'] == 'middle')\n",
    "n_hi  = np.sum(data['social_factor_bin'] == 'high')\n",
    "\n",
    "print(f'Low: {n_low} ({n_low/len(data)*100:.2f}%)')\n",
    "print(f'Mid: {n_mid} ({n_mid/len(data)*100:.2f}%)')\n",
    "print(f'Hi:  {n_hi} ({n_hi/len(data)*100:.2f}%)')\n",
    "\n",
    "#--------------------------------------------\n",
    "# plot\n",
    "#--------------------------------------------\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7, 4))\n",
    "\n",
    "ax = axs[0]\n",
    "plot_histplot(data[social_factor], ax=ax, color='grey', bins=20)\n",
    "ax.axvline(bottom, color='black', linestyle='--')\n",
    "ax.axvline(top, color='black', linestyle='--')\n",
    "\n",
    "ax = axs[1]\n",
    "sns.barplot(x='social_factor_bin', y='pov_2d_dist_mean_mean', \n",
    "            data=data, ax=ax, palette='Greys', edgecolor='black', linewidth=1)\n",
    "sns.stripplot(x='social_factor_bin', y='pov_2d_dist_mean_mean',\n",
    "              data=data, ax=ax, palette='Greys', s=5, edgecolor='black', linewidth=1, alpha=.25)\n",
    "ax.set_xlabel('Social factor', fontsize=label_fontsize)\n",
    "# ax.set_xticklabels(['Low', 'Middle', 'High'])\n",
    "ax.set_ylim(3.3, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maybe small relationships to task memory, task engagement etc\n",
    "\n",
    "slight positive trend w/ memory and w/ relatability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
    "\n",
    "# memory for task\n",
    "ax = axs[0]\n",
    "sns.regplot(x='memory_mean', y='affil_mean_mean', data=data, ax=ax)\n",
    "sns.regplot(x='memory_mean', y='power_mean_mean', data=data, ax=ax)\n",
    "ax.set_ylabel('Dimension tendency')\n",
    "\n",
    "# engagement with task\n",
    "storyline_cols = ['storyline_engagement', 'storyline_difficulty', 'storyline_relatability']\n",
    "mask = np.isfinite(data['storyline_difficulty'])\n",
    "for c, col in enumerate(storyline_cols):\n",
    "    ax = axs[1+c]\n",
    "    sns.regplot(x=col, y='affil_mean_mean', data=data[mask], ax=ax)\n",
    "    sns.regplot(x=col, y='power_mean_mean', data=data[mask], ax=ax)\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trying to relate beta dissimilarities to semantics using an RSa\n",
    "# ols_items['abs_beta'] = ols_items['beta'].abs()\n",
    "# ols_items_ = ols_items.pivot(index=['item', 'text'], columns='dimension', values='abs_beta').reset_index()\n",
    "# ols_items_.columns.name = None\n",
    "# item_rdm = pairwise_distances(ols_items_[['affil_mean_mean', 'power_mean_mean']], metric='cosine') # captures the similarity in the relationship strength between items and dimensions\n",
    "# plot_rdm(item_rdm, figsize=(5,5));\n",
    "\n",
    "# vectors = get_sentencetransformer_embeddings(ols_items_['text'].values, model='roberta')\n",
    "# semantic_rdm = pairwise_distances(vectors, metric='cosine')\n",
    "# item_rdv = symm_mat_to_ut_vec(item_rdm)\n",
    "# semantic_rdv = symm_mat_to_ut_vec(semantic_rdm)\n",
    "# tau, p = kendalltau(item_rdv, semantic_rdv, alternative='greater')\n",
    "# print(f'Kendall\\'s tau: {tau:.3f}, p={p:.3f}')\n",
    "\n",
    "# # IS-RSA\n",
    "# ques_df = subset_df(data, fa_prefixes)\n",
    "# ques_items = ques_df.iloc[:, 1:].values\n",
    "# ques_items = np.nan_to_num(ques_items, nan=np.nanmean(ques_items, axis=0))\n",
    "# ques_rdm = pairwise_distances(ques_items, metric='cosine')\n",
    "# # plot_rdm(ques_rdm, figsize=(8, 8));\n",
    "\n",
    "# ols_res, ols_individ_res = [], []\n",
    "# for yvar in ['affil_mean_mean', 'power_mean_mean']:\n",
    "#     ols_df = run_ols(X=top_items, y=yvar, data=df)[0]\n",
    "#     ols_res.append(ols_df[ols_df['x'].isin(top_items)])\n",
    "#     for item in top_items:\n",
    "#         ols_df = run_ols(X=item, y=yvar, data=df)[0]\n",
    "#         ols_individ_res.append(ols_df[ols_df['x'].isin([item])])\n",
    "# top_ques = np.unique([q.split('_')[0] for q in top_items])\n",
    "# print(top_ques)\n",
    "\n",
    "# # turn ols_items into wide format\n",
    "# ols_items_wide = ols_items.pivot(index='item', columns='dimension', values='beta')\n",
    "# ols_items_wide = ols_items_wide.reset_index()\n",
    "# ols_items_wide.columns.name = None\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# ols_items_wide['affil_mean_mean_scaled'] = scaler.fit_transform(ols_items_wide['affil_mean_mean'].values[:,np.newaxis])\n",
    "# ols_items_wide['power_mean_mean_scaled'] = scaler.fit_transform(ols_items_wide['power_mean_mean'].values[:,np.newaxis])\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "# sns.scatterplot(ax=ax, \n",
    "#                 x=ols_items_wide['affil_mean_mean_scaled'], \n",
    "#                 y=ols_items_wide['power_mean_mean_scaled'], s=75, alpha=1)\n",
    "# plot_social_space(ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic embeddings\n",
    "probably too naive of an approach rn... have to transform the questionnaire text appropriately - how do I account for the diff. question types etc?\n",
    "- some items are reverse coded\n",
    "- others had reverse rating instructions... e.g., how much you avoid this, etc...\n",
    "- so the scores and text relationship might need to be flipped for these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_variance(X, standardize=True, plot=True, tangent=True, title=None):\n",
    "    \"\"\"\n",
    "    Perform PCA and plot the cumulative variance explained as a function of the number of components.\n",
    "\n",
    "    Parameters:\n",
    "    - X: ndarray\n",
    "        The input data matrix where each row is a sample and each column is a feature.\n",
    "    - standardize: bool\n",
    "        Whether to standardize the data before performing PCA.\n",
    "\n",
    "    Returns:\n",
    "    - cumulative_variance: ndarray\n",
    "        Array containing the cumulative variance explained by each component.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Standardize the data if needed\n",
    "    if standardize:\n",
    "        scaler = sklearn.preprocessing.StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform PCA & calculate the variance explained\n",
    "    pca = PCA().fit(X)\n",
    "    explained_variance  = pca.explained_variance_ratio_\n",
    "    cumulative_variance = np.cumsum(explained_variance)\n",
    "    \n",
    "    # Plotting\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.bar(range(1, len(cumulative_variance) + 1), explained_variance, alpha=1, color='grey', label='Individual')\n",
    "        plt.step(range(1, len(cumulative_variance) + 1), cumulative_variance, where='mid', color='grey', label='Cumulative')\n",
    "        plt.xlabel('Number PCs', fontsize=label_fontsize)\n",
    "        # change x-ticks by + 1\n",
    "        # plt.xticks(np.arange(1, len(cumulative_variance) + 1, 50))\n",
    "\n",
    "        for color, cvar in {'orange': 0.5, 'orangered': 0.75, 'red': 0.9}.items():\n",
    "            x = np.argmax(cumulative_variance >= cvar) + 1\n",
    "            plt.scatter(x, cvar, marker='x', color=color, s=200, zorder=10)\n",
    "            plt.text(x + 3, cvar, f'{int(cvar*100)}%={x} PCs', fontsize=15, color=color)\n",
    "\n",
    "            if tangent:\n",
    "                # add the tangent line at this point\n",
    "                # find slope of tangent line by finding f'(x)\n",
    "                # https://stackoverflow.com/questions/3985619/how-to-calculate-a-tangent-line-along-a-curve\n",
    "                x1, y1 = x, cumulative_variance[x]\n",
    "                x2, y2 = x+1, cumulative_variance[x+1]\n",
    "                m = (y2 - y1) / (x2 - x1)\n",
    "                x = np.linspace(0, 100, 100) # evaluate it at all these points\n",
    "                y = m * (x - x1) + y1\n",
    "                plt.plot(x, y, color=color, linestyle='-', linewidth=2, alpha=0.25)\n",
    "\n",
    "        plt.ylim(0, 1)\n",
    "        plt.ylabel('Explained Variance', fontsize=label_fontsize)\n",
    "        title = title or 'Variance Explained'\n",
    "        if standardize: title += ' (standardized)'\n",
    "        plt.title(title, fontsize=title_fontsize)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return cumulative_variance\n",
    "# plot_cumulative_variance(vectors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_value = 1\n",
    "# n_items = np.sum(np.abs(ols_res['t']) > t_value)\n",
    "# print(f'Number of items with |t| > {t_value}: {n_items}')\n",
    "\n",
    "# # the beta weights for the top N items\n",
    "# ols_rdm = pairwise_distances(ols_items_wide[['affil_mean_mean', 'power_mean_mean']].iloc[:n_items, :], metric='euclidean')\n",
    "# ols_rdv = symm_mat_to_ut_vec(ols_rdm)\n",
    "\n",
    "# # the embedding vectors\n",
    "# vectors = get_sentencetransformer_embeddings(ols_items['text'].values[::2][:n_items], model='roberta')\n",
    "# pca = PCA().fit_transform(vectors)\n",
    "# embedding_rdm = pairwise_distances(pca[:, :10], metric='euclidean')\n",
    "# embedding_rdv = symm_mat_to_ut_vec(embedding_rdm)\n",
    "\n",
    "# # rsa\n",
    "# tau, p = kendalltau(embedding_rdv, ols_rdv, alternative='greater')\n",
    "# ols_perms = permute_symm_mat(ols_rdm, n_perms=1000)\n",
    "# perm_taus = np.array([kendalltau(embedding_rdv, symm_mat_to_ut_vec(perm))[0] for perm in ols_perms])\n",
    "# perm_p = calc_perm_pvalue(tau, perm_taus, alternative='greater')\n",
    "# print(f'Tau = {tau:.3f}, p = {p:.3f}, perm p = {perm_p:.3f}')\n",
    "\n",
    "# # plot\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "# plot_histplot(perm_taus, ax=ax);\n",
    "# ax.axvline(tau, color='red', linestyle='--', linewidth=2)\n",
    "# ax.set_xlabel('Kendall tau', fontsize=label_fontsize);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_df = pd.DataFrame(pca[:,:3], columns=['x', 'y', 'z'])\n",
    "# fig = px.scatter_3d(pca_df, x='x', y='y', z='z', \n",
    "#                     # text=factor_top['text'].values,\n",
    "#                     size_max=10, opacity=0.7)\n",
    "# fig.update_layout(font = dict(family=\"Arial\", size=10, color=\"black\"))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = data_val[['pov_2d_dist_mean_mean', 'affil_mean_mean', 'power_mean_mean', 'memory_mean',\n",
    "              'num_words_mean', 'compound_mean', 'positive_mean', 'negative_mean', 'neutral_mean',\n",
    "               social_factor, mood_factor, compulsive_factor, \n",
    "              'dots_area', 'beh_dots_procrustes_disp', 'beh_dots_dist_memory_tau']].corr()\n",
    "sns.heatmap(C, vmin=-1, vmax=1, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2, 2, figsize=(4, 4), sharey=True)\n",
    "fig.text(0.5, -0.05, 'Overlap', ha='center', fontdict={'fontsize':14})\n",
    "fig.text(-0.05, 0.5, 'Memory', va='center', rotation='vertical', fontdict={'fontsize':14})\n",
    "for i,r in enumerate([1,0,3,2]):\n",
    "    ax = axs[i//2, i%2]\n",
    "    sns.regplot(ax=ax, x=f'Q{r+1}_overlap', y='memory_mean', data=data, \n",
    "                line_kws={'color':'black', 'linewidth':2},\n",
    "                color='grey', scatter_kws={'s':20, 'edgecolor':'black', 'alpha':.25})\n",
    "    ax.set_title(f'Q{r+1}', fontdict={'fontsize':20})\n",
    "    ax.set_xticks([0, .5, 1])\n",
    "    ax.set_yticks([0, .5, 1])\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(6,3))\n",
    "sns.histplot(ax=axs[0], x=data['prospective_choice_rt_avg'], bins=20)\n",
    "sns.regplot(ax=axs[1], x='prospective_choice_rt_avg', y='prospective_choice_pref_avg', data=data,\n",
    "            scatter_kws={'alpha':0.5, 's':30})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People want the powerful person in their network most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data[[f'prospective_{role}_mean' for role in character_roles]]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "sns.barplot(data_, alpha=0.5, palette='colorblind', edgecolor='black', linewidth=1, ci=None, ax=ax)\n",
    "sns.stripplot(data_, palette='colorblind', edgecolor='black', linewidth=0.5, ax=ax)\n",
    "ax.set_xticklabels(character_roles, rotation=80, horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrusive factor has a correlation w/ average preference (not strong though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(9, 3))\n",
    "for i, factor in enumerate(factor_labels): \n",
    "    plot_regplot(data['prospective_choice_pref_avg'], data[factor], ax=axs[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use MLPRegressor on all combinations of Xs to predict factor_social_min and choose best model by accuracy\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from itertools import combinations\n",
    "\n",
    "Xs = ['likability_selfOther_avg', 'impact_selfOther_diff', 'pov_2d_dist_mean', 'affil_mean_mean', 'power_mean_mean']   \n",
    "# get all possible combinations of Xs\n",
    "Xs_combos = []\n",
    "for i in range(1, len(Xs)+1):\n",
    "    Xs_combos += list(combinations(Xs, i))\n",
    "\n",
    "# store performane\n",
    "performance = {}\n",
    "\n",
    "# loop over Xs_combos and train MLPRegressor on each\n",
    "for X in Xs_combos:\n",
    "\n",
    "    # mask with np.isfinite\n",
    "    mask = np.isfinite(data[list(X) + [social_factor]]).all(1)\n",
    "    data_ = data[mask]\n",
    "\n",
    "    # split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_[list(X)], \n",
    "                                                        data_[social_factor], \n",
    "                                                        test_size=0.2, random_state=42)\n",
    "\n",
    "    # MLPRegressor\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(10,10), activation='relu', solver='adam', max_iter=100, random_state=42)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    \n",
    "    # diff metrics\n",
    "    mse = np.mean((y_test - y_pred)**2)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_adj = adj_r2(r2, X_test.shape[0], X_test.shape[1])\n",
    "\n",
    "    # join each element of X into a string\n",
    "    X = ','.join(X)\n",
    "\n",
    "    # store performance\n",
    "    performance[X] = {'mse': mse, 'r2': r2, 'r2_adj': r2_adj}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the keys by r2_adj\n",
    "performance = {k: v for k, v in sorted(performance.items(), key=lambda item: item[1]['r2_adj'], reverse=True)}\n",
    "# get first key\n",
    "best_model = list(performance.keys())[0]\n",
    "print(f'Best model: {best_model}')\n",
    "print(f'Performance: {performance[best_model]}')\n",
    "\n",
    "# use best model to predict factor_social_min with linear regression\n",
    "ols_obj = run_ols(best_model.split(','), social_factor, data, covariates=demo_controls)[1]\n",
    "print(ols_obj.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------\n",
    "# EXPERIMENTAL\n",
    "# -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCA: good correlations - do more here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dim_reduction import CrossDecompose\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.cross_decomposition import CCA, PLSRegression, PLSCanonical\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def clean_data(data, yvars, xvars, var_thresh=0.0):\n",
    "    # X = data[xvars].dropna() # drop rows with nans\n",
    "    # use np.isfinite to drop rows with nan\n",
    "    \n",
    "    fin_mask = np.isfinite(data[xvars + yvars]).all(1)\n",
    "    conds = data[fin_mask]['sample'].values\n",
    "    Y = data[fin_mask][yvars].reset_index(drop=True)\n",
    "\n",
    "    # clean up X \n",
    "    X = data[fin_mask][xvars].reset_index(drop=True)\n",
    "    vt = VarianceThreshold(threshold = var_thresh) #Removing both constant and quasi-constant\n",
    "    vt.fit(X)\n",
    "    X = X.loc[:, vt.get_support()]\n",
    "\n",
    "    assert not np.any(np.isnan(X)), 'X has nans'\n",
    "    assert not np.any(np.isnan(Y)), 'Y has nans'\n",
    "    print(f'X shape: {X.shape}, Y shape: {Y.shape}')\n",
    "    return X, Y, conds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m yvars_ \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maffil_mean_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpower_mean_mean\u001b[39m\u001b[38;5;124m'\u001b[39m], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpov_2d_dist_mean_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;66;03m#, ['pov_dist_mean', 'pov_2d_angle_mean_mean']]\u001b[39;00m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m yvars \u001b[38;5;129;01min\u001b[39;00m yvars_:\n",
      "\u001b[1;32m      7\u001b[0m \n",
      "\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# remove yvars frm xvars\u001b[39;00m\n",
      "\u001b[0;32m----> 9\u001b[0m     X, Y, conds \u001b[38;5;241m=\u001b[39m \u001b[43mclean_data\u001b[49m(data, yvars, x_cols, var_thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\n",
      "\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# split X and Y into train/test balancing on condition\u001b[39;00m\n",
      "\u001b[1;32m     12\u001b[0m     sss \u001b[38;5;241m=\u001b[39m StratifiedShuffleSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.50\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m35\u001b[39m)\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_data' is not defined"
     ]
    }
   ],
   "source": [
    "x_cols = [social_factor, 'demo_ladder_rate', 'sni_number_ppl', 'sni_network_diversity','likability_relationship_mean', 'impact_relationship_mean', \n",
    "          'self_likability', 'self_impact']\n",
    "y_cols = ['pov_2d_dist_mean_mean', 'affil_mean_mean', 'power_mean_mean', 'pov_2d_angle_mean_mean']\n",
    "yvars_ = [['affil_mean_mean', 'power_mean_mean'], ['pov_2d_dist_mean_mean']] #, ['pov_dist_mean', 'pov_2d_angle_mean_mean']]\n",
    "\n",
    "for yvars in yvars_:\n",
    "\n",
    "    # remove yvars frm xvars\n",
    "    X, Y, conds = clean_data(data, yvars, x_cols, var_thresh=0.0)\n",
    "\n",
    "    # split X and Y into train/test balancing on condition\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.50, random_state=35)\n",
    "    splits = list(sss.split(np.arange(len(conds)), conds))\n",
    "    train_ix, test_ix = splits[0][0], splits[0][1]\n",
    "\n",
    "    X_train, Y_train = X.iloc[train_ix, :], Y.iloc[train_ix, :]\n",
    "    X_test, Y_test   = X.iloc[test_ix, :], Y.iloc[test_ix, :]\n",
    "    conds_test, conds_train = conds[test_ix], conds[train_ix]\n",
    "\n",
    "    assert len(X_train) == len(Y_train), 'X_train and Y_train have different lengths'\n",
    "    assert len(X_test) == len(Y_test), 'X_test and Y_test have different lengths'\n",
    "\n",
    "    #--------------------------------------------------------------------------------------\n",
    "    # run pls: CV to select n_comps, then validate on test_set\n",
    "    #--------------------------------------------------------------------------------------\n",
    "\n",
    "    # zscore X and Y for train and test separately\n",
    "    X_train, Y_train = scipy.stats.zscore(X_train), scipy.stats.zscore(Y_train) \n",
    "    X_test, Y_test   = scipy.stats.zscore(X_test), scipy.stats.zscore(Y_test) \n",
    "\n",
    "    assert not np.any(np.isnan(X_train)), 'X_train has nans'\n",
    "    assert not np.any(np.isnan(Y_train)), 'Y_train has nans'\n",
    "    assert not np.any(np.isnan(X_test)), 'X_test has nans'\n",
    "    assert not np.any(np.isnan(Y_test)), 'Y_test has nans'\n",
    "\n",
    "    # select n_comps w/ 5 fold CV on training data\n",
    "    loadings = {}\n",
    "    pls = CrossDecompose(n_comps=5, scale=False, mode='pls')\n",
    "    pls.optimize_fit(X_train, Y_train, max_comps=None, folds=5, metric='MSE', plot=False, colors=None)\n",
    "    # pls.fit(X_train, Y_train)\n",
    "    loadings['optimization'] = pls.X_loadings\n",
    "    top_features = pls.get_top_features(n_features=30) # get top features for diff components\n",
    "\n",
    "    _ = pls.predict(X_test, Y_test, plot=True)\n",
    "    pls.plot_X_loadings()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.multivariate.cancorr import CanCorr\n",
    "Y = data[['likability_relationship_mean', 'impact_relationship_mean']] # y is the relationship likability and impact\n",
    "\n",
    "Xs = [['self_likability', 'self_impact'], \n",
    "      ['affil_mean_mean', 'power_mean_mean']]\n",
    "for X_ in Xs:\n",
    "    X = data[X_] # X is self likability and self impac\n",
    "    mask = (np.sum(np.isfinite(X),1) == X.shape[1]) & (np.sum(np.isfinite(Y),1) == Y.shape[1])\n",
    "    cca = CanCorr(X[mask], Y[mask])\n",
    "    print(cca.corr_test().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data consistent with a mediation of this sort: self-place -> social approach/avoid -> behavioral distancing/SNI etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mediation(x, m, y, df, covs):\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    # preprpocess the data\n",
    "\n",
    "    data = df.copy()\n",
    "    \n",
    "    # mask out non-responses\n",
    "    all_vars = [x,y,m] + covs\n",
    "    mask = np.sum(np.isfinite(data[[x,y,m] + covs]), 1) == len(all_vars)\n",
    "    data = data[mask]\n",
    "\n",
    "    print(f'testing: {x} -> {m} -> {y}')\n",
    "    print(f'n={data.shape[0]}')\n",
    "\n",
    "    # dummy code, zscore\n",
    "    for v in [x, y, m] + covs:\n",
    "        if type(v) == str: data[v] = data[v].astype('category').cat.codes        \n",
    "        data[v] = zscore(data[v])\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    # run mediation analysis\n",
    "    # - y ~ x   \n",
    "    reg = run_ols([x], y, data, covariates=covs)[1]\n",
    "    x_ = [n for n in reg.pvalues.index if x in n][0] # jic its categorical\n",
    "    [p1, b1] = reg.pvalues[x_], reg.params[x_]\n",
    "\n",
    "    # - m ~ x\n",
    "    reg = run_ols([x], m, data, covariates=covs)[1]\n",
    "    [p2, b2] = reg.pvalues[x_], reg.params[x_]\n",
    "\n",
    "    # - y ~ m\n",
    "    reg = run_ols([m], y, data, covariates=covs)[1]\n",
    "    [p3, b3] = reg.pvalues[m], reg.params[m]\n",
    "\n",
    "    # - y ~ x + m\n",
    "    reg = run_ols([x, m], y, data, covariates=covs)[1]\n",
    "    [p4, b4] = reg.pvalues[x_], reg.params[x_]\n",
    "    \n",
    "    # stack the ps and betas\n",
    "    res = np.array([[p1, p2, p3, p4], \n",
    "                    [b1, b2, b3, b4]]).T\n",
    "\n",
    "    # make a dataframe\n",
    "    res = pd.DataFrame(res, columns=['p', 'beta(z)'], index=['y~x', 'm~x', 'y~m', 'y~x+m'])\n",
    "    res = res.applymap(lambda x: '{:.7f}'.format(x))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # can we do a mediation analysis with only measured features? e.g., no causal manipulaion...\n",
    "# # self location -> social avoidance -> behavioral distancing, network features, etc...\n",
    "\n",
    "# models = [['self_impact', 'demo_ladder_rate', 'factor_social'],\n",
    "#           ['demo_ladder_rate', 'self_impact', 'factor_social'],\n",
    "#           ['self_likability', 'demo_ladder_rate', 'factor_social'],\n",
    "#           ['demo_ladder_rate', 'self_likability', 'factor_social'],\n",
    "#           ['self_impact', 'demo_ladder_rate', 'pov_2d_dist_mean'],\n",
    "#           ['self_likability', 'demo_ladder_rate', 'pov_2d_dist_mean'],\n",
    "#           ['self_impact', 'factor_social', 'pov_2d_dist_mean'],\n",
    "#           ['factor_social', 'self_impact', 'pov_2d_dist_mean'],\n",
    "#           ['self_likability', 'factor_social', 'pov_2d_dist_mean'],\n",
    "#           ['factor_social', 'self_likability', 'pov_2d_dist_mean']]\n",
    "\n",
    "# ys = ['sni_network_diversity', 'sni_number_ppl']\n",
    "\n",
    "# for mod in models:\n",
    "#     display(run_mediation(mod[0], mod[1], mod[2], data, demo_controls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.mediation import Mediation\n",
    "\n",
    "# ACME: average causal mediation effect - the indirect effect of X on Y through M\n",
    "# ADE: average direct effect - direct effect of X on Y\n",
    "# total effect: driect + indirect of X on Y\n",
    "# prop mediated: proportion of effect of X on Y mediated by M\n",
    "\n",
    "x, m, y  = 'self_likability', social_factor, 'pov_2d_dist_mean_mean_z'\n",
    "all_vars = [x, y, m] + demo_controls\n",
    "mask     = np.sum(np.isfinite(data[all_vars]), 1) == len(all_vars)\n",
    "\n",
    "# family = sm.families.Binomial(link=links.probit())\n",
    "demo_str = (' + ').join(demo_controls)\n",
    "outcome_model  = sm.GLM.from_formula(f\"{y} ~ {x} + {m} + {demo_str}\", data[mask])\n",
    "mediator_model = sm.OLS.from_formula(f\"{m} ~ {x} + {demo_str}\",  data[mask])\n",
    "mediation = Mediation(outcome_model, mediator_model, x, m).fit()\n",
    "mediation.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social_navigation_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "afb432af2a6d4e683b6deca85d226b121832fa8b450f98b144295a2f52816835"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
